# Inference.py å·¥ä½œåŸç†ä¸è¯„ä¼°æŒ‡å—

## ğŸ“– ç›®å½•
1. [Inference.py Pipeline è¯¦è§£](#inference-pipeline)
2. [å¦‚ä½•éªŒè¯ä¿®å¤æ•ˆæœ](#éªŒè¯ä¿®å¤æ•ˆæœ)
3. [ä½¿ç”¨ Evaluation å·¥å…·](#ä½¿ç”¨evaluationå·¥å…·)
4. [å¿«é€Ÿå¼€å§‹æŒ‡å—](#å¿«é€Ÿå¼€å§‹)

---

## ğŸ” Inference Pipeline è¯¦è§£

### æ ¸å¿ƒæ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Inference.py Pipeline                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è¾“å…¥ â†’ æ•°æ®åŠ è½½ â†’ æ¨¡å‹æ¨ç† â†’ æŒ‡æ ‡è®¡ç®— â†’ å¯è§†åŒ–è¾“å‡º
 â”‚        â”‚           â”‚           â”‚           â”‚
 â”‚        â”‚           â”‚           â”‚           â””â”€â†’ å›¾ç‰‡/è§†é¢‘
 â”‚        â”‚           â”‚           â””â”€â†’ PSNR/SSIM/LPIPS
 â”‚        â”‚           â””â”€â†’ ç¼–ç /è§£ç 
 â”‚        â””â”€â†’ MiniDataset
 â””â”€â†’ åŸå§‹è§†é¢‘
```

### è¯¦ç»†æ•°æ®æµ

```python
# ============================================
# å®Œæ•´æ•°æ®æµè¿½è¸ª
# ============================================

Step 1: è¾“å…¥
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- annotation_file: JSONæ–‡ä»¶è·¯å¾„
- data_root: è§†é¢‘æ–‡ä»¶ç›®å½•
- model_path: è®­ç»ƒå¥½çš„æ¨¡å‹checkpoint

Step 2: æ•°æ®åŠ è½½ (Line 444)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
dataset = MiniDataset(
    annotation_file=annotation_file,
    data_dir=dataset_path,
    patch_hw=128,      # patchå¤§å°
    n_frames=12        # å¸§æ•°
)
â†“
è¾“å‡º: Datasetå¯¹è±¡ (500ä¸ªæ ·æœ¬)

Step 3: å•æ ·æœ¬å¤„ç† (Line 455-457)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
sample = dataset[i]                        # [T, C, H, W]
frames = sample.unsqueeze(0).float()       # [1, T, C, H, W]
                                           # âœ… å·²ç»æ˜¯ [0,1] (ä¿®å¤å)
frames = frames.to(device)                 # ç§»åˆ°GPU
â†“
æ•°æ®èŒƒå›´: [0, 1] float32
å½¢çŠ¶: [1, 12, 3, 128, 128]

Step 4: æ¨¡å‹ç¼–ç  (Line 465)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
encoded = model.encode_video(frames, parallel=True)
â†“
æ½œåœ¨è¡¨ç¤º (latent): [1, latent_dim, ...]
å‹ç¼©æ¯”: ~8-16x

Step 5: æ¨¡å‹è§£ç  (Line 471)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
decoded = model.decode_video(encoded, parallel=True)
â†“
é‡å»ºè§†é¢‘: [1, 12, 3, 128, 128], [0, 1]

Step 6: æŒ‡æ ‡è®¡ç®— (Line 477)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
metrics = calculate_comprehensive_metrics(frames, decoded)
â†“
- MSE: å‡æ–¹è¯¯å·®
- PSNR: å³°å€¼ä¿¡å™ªæ¯” (è¶Šé«˜è¶Šå¥½, >30 excellent)
- SSIM: ç»“æ„ç›¸ä¼¼åº¦ (è¶Šæ¥è¿‘1è¶Šå¥½)
- LPIPS: æ„ŸçŸ¥æŸå¤± (è¶Šä½è¶Šå¥½)

Step 7: è¾“å‡ºç”Ÿæˆ (Line 497-503)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- åŸå§‹è§†é¢‘
- é‡å»ºè§†é¢‘
- å¯¹æ¯”è§†é¢‘ (side-by-side)
- æ½œåœ¨è¡¨ç¤ºå¯è§†åŒ–
- æŒ‡æ ‡æŠ¥å‘Š (JSON)
- HTMLæŠ¥å‘Š
```

### å…³é”®ç»„ä»¶è¯´æ˜

#### 1. TAEHVInference ç±»

```python
class TAEHVInference:
    """å®Œæ•´çš„TAEHVæ¨ç†å™¨"""
    
    def __init__(self, model_path, device="cuda"):
        # ç»„ä»¶1: åŠ è½½æ¨¡å‹
        self.model = self.load_model(model_path)
        
        # ç»„ä»¶2: åˆå§‹åŒ–æŒ‡æ ‡è®¡ç®—å™¨
        self.ssim = StructuralSimilarityIndexMeasure()
        self.lpips = LearnedPerceptualImagePatchSimilarity()
```

**ä½œç”¨**: å°è£…äº†æ¨¡å‹åŠ è½½ã€æ¨ç†ã€æŒ‡æ ‡è®¡ç®—çš„å®Œæ•´æµç¨‹

#### 2. æ ¸å¿ƒæ–¹æ³•

| æ–¹æ³• | ä½œç”¨ | è¾“å…¥ | è¾“å‡º |
|------|------|------|------|
| `load_model()` | åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ | model_path | TAEHVæ¨¡å‹ |
| `calculate_comprehensive_metrics()` | è®¡ç®—è´¨é‡æŒ‡æ ‡ | original, reconstructed | metrics dict |
| `run_inference()` | æ‰§è¡Œå®Œæ•´æ¨ç†æµç¨‹ | dataseté…ç½® | ç»“æœæ–‡ä»¶ |
| `create_structured_output()` | ç”Ÿæˆå¯è§†åŒ–è¾“å‡º | frames, metrics | å›¾ç‰‡/è§†é¢‘ |

#### 3. è¾“å…¥å‚æ•°

```python
# inference.py æ¥å—çš„å‚æ•°
--model_path        # æ¨¡å‹checkpointè·¯å¾„ (å¿…éœ€)
--data_root         # è§†é¢‘æ•°æ®ç›®å½•
--annotation_file   # JSONæ³¨è§£æ–‡ä»¶
--num_samples       # æµ‹è¯•æ ·æœ¬æ•° (é»˜è®¤10)
--output_dir        # è¾“å‡ºç›®å½•
--device            # è®¾å¤‡ (cuda/cpu)
--output_format     # è¾“å‡ºæ ¼å¼ (simple/enhanced/complete)
--use_ref_vae       # æ˜¯å¦ä½¿ç”¨å‚è€ƒVAEå¯¹æ¯”
```

#### 4. è¾“å‡ºç»“æ„

```
output_dir/
â”œâ”€â”€ sample_000_original.mp4         # åŸå§‹è§†é¢‘
â”œâ”€â”€ sample_000_reconstructed.mp4    # é‡å»ºè§†é¢‘
â”œâ”€â”€ sample_000_comparison.mp4       # å¯¹æ¯”è§†é¢‘
â”œâ”€â”€ sample_000_latents.png          # æ½œåœ¨è¡¨ç¤ºå¯è§†åŒ–
â”œâ”€â”€ sample_000_metrics.json         # è¯¦ç»†æŒ‡æ ‡
â”œâ”€â”€ inference_results.json          # æ€»ä½“ç»“æœ
â””â”€â”€ inference_report.html           # HTMLæŠ¥å‘Š
```

---

## âœ… éªŒè¯ä¿®å¤æ•ˆæœ

### æ–¹æ³• 1: ç›´æ¥ä½¿ç”¨ inference.pyï¼ˆéœ€è¦å·²è®­ç»ƒæ¨¡å‹ï¼‰

**å‰æ**: ä½ éœ€è¦æœ‰ä¸€ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹checkpoint

#### Step 1: æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨æ¨¡å‹

```bash
# æŸ¥æ‰¾æ‰€æœ‰æ¨¡å‹æ–‡ä»¶
find outputs -name "*.safetensors" -o -name "*.pth" 2>/dev/null

# æŸ¥çœ‹æœ€æ–°çš„æ¨¡å‹
ls -lht outputs/*/checkpoints/*.pth | head -5
```

#### Step 2: è¿è¡Œæ¨ç†æµ‹è¯•

```bash
# å‡è®¾æ‰¾åˆ°äº†æ¨¡å‹: outputs/taehv_run1/checkpoints/checkpoint-1000.pth

python inference.py \
    --model_path outputs/taehv_run1/checkpoints/checkpoint-1000.pth \
    --annotation_file /data/matrix-project/MiniDataset/stage1_annotations_500.json \
    --data_root /data/matrix-project/MiniDataset/data \
    --num_samples 10 \
    --output_dir evaluation/evaluation_results/after_fix \
    --output_format enhanced
```

#### Step 3: æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡

```bash
# æŸ¥çœ‹è¾“å‡ºç›®å½•
ls -lh evaluation/evaluation_results/after_fix/

# åº”è¯¥çœ‹åˆ°:
# - sample_000_original.mp4
# - sample_000_reconstructed.mp4
# - sample_000_comparison.mp4
# - ...
```

#### æœŸæœ›ç»“æœï¼ˆä¿®å¤åï¼‰

âœ… **æˆåŠŸæ ‡å¿—**:
- é‡å»ºè§†é¢‘**ä¸æ˜¯å…¨é»‘**
- PSNR > 15 (ç†æƒ³æƒ…å†µ > 25)
- SSIM > 0.5 (ç†æƒ³æƒ…å†µ > 0.8)
- è§†è§‰ä¸Šå¯ä»¥çœ‹åˆ°å†…å®¹

âŒ **å¤±è´¥æ ‡å¿—**ï¼ˆä¿®å¤å‰çš„ç—‡çŠ¶ï¼‰:
- é‡å»ºè§†é¢‘å…¨é»‘æˆ–æ¥è¿‘å…¨é»‘
- PSNR < 10
- SSIM < 0.3
- å®Œå…¨çœ‹ä¸åˆ°å†…å®¹

---

## ğŸ¯ ä½¿ç”¨ Evaluation å·¥å…·

### Option 1: evaluate_vae.pyï¼ˆæœ€å…¨é¢ï¼‰

**åŠŸèƒ½**: å®Œæ•´çš„æ¨¡å‹è¯„ä¼°ï¼ŒåŒ…æ‹¬å®šé‡æŒ‡æ ‡å’Œå¯è§†åŒ–

```bash
# åŸºç¡€ç”¨æ³•
python evaluation/evaluate_vae.py \
    --model_path <æ¨¡å‹è·¯å¾„> \
    --annotation_file /data/matrix-project/MiniDataset/stage1_annotations_500.json \
    --data_root /data/matrix-project/MiniDataset/data \
    --num_samples 50 \
    --output_dir evaluation/evaluation_results/full_eval
```

**è¾“å‡º**:
- å®šé‡æŒ‡æ ‡æŠ¥å‘Š
- é‡å»ºè´¨é‡å¯è§†åŒ–
- æ½œåœ¨ç©ºé—´åˆ†æ
- å¯¹æ¯”å›¾è¡¨

### Option 2: quick_evaluate.pyï¼ˆä¸€é”®è¯„ä¼°ï¼‰

**åŠŸèƒ½**: è‡ªåŠ¨åŒ–è¯„ä¼°æµç¨‹

```bash
# è¿›å…¥evaluationç›®å½•
cd evaluation

# è¿è¡Œå¿«é€Ÿè¯„ä¼°
python quick_evaluate.py \
    --model_path ../outputs/taehv_run1/checkpoints/checkpoint-1000.pth \
    --config ../training/configs/taehv_config_a800.py \
    --num_samples 50 \
    --output_dir evaluation_results/quick_eval
```

**åŒ…å«**:
1. è®­ç»ƒæ—¥å¿—åˆ†æ
2. æ¨¡å‹å®šé‡è¯„ä¼°
3. ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š

### Option 3: quick_evaluate.shï¼ˆShellè„šæœ¬ï¼‰

**åŠŸèƒ½**: é¢„é…ç½®çš„è¯„ä¼°è„šæœ¬

```bash
# æŸ¥çœ‹è„šæœ¬å†…å®¹
cat evaluation/quick_evaluate.sh

# ä¿®æ”¹è„šæœ¬ä¸­çš„è·¯å¾„
# MODEL_PATH="..."
# OUTPUT_DIR="..."

# è¿è¡Œ
bash evaluation/quick_evaluate.sh
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼šéªŒè¯ä¿®å¤æ•ˆæœ

### åœºæ™¯ 1: æ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹

**æ— æ³•ä½¿ç”¨ inference.pyï¼Œä½†å¯ä»¥éªŒè¯æ•°æ®**

```bash
# å·²ç»å®Œæˆï¼ä½ ä¹‹å‰è¿è¡Œçš„è¿™ä¸ªå°±æ˜¯éªŒè¯
python scripts/check_dataset_output.py \
    --annotation_file /data/matrix-project/MiniDataset/stage1_annotations_500.json \
    --data_root /data/matrix-project/MiniDataset/data \
    --num_samples 5

# ç»“æœ: âœ… æ•°æ®èŒƒå›´ [0, 1]ï¼Œä¿®å¤æˆåŠŸ
```

**ä¸‹ä¸€æ­¥**: è®­ç»ƒä¸€ä¸ªæ¨¡å‹

```bash
# å¿«é€Ÿè®­ç»ƒæµ‹è¯•ï¼ˆ100æ­¥ï¼‰
accelerate launch --config_file configs/accelerate_config.yaml \
    training/taehv_train.py \
    --config training/configs/taehv_config_a800.py
```

### åœºæ™¯ 2: æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹

**Step 1**: æ‰¾åˆ°æ¨¡å‹è·¯å¾„

```bash
MODEL_PATH=$(find outputs -name "*.pth" -type f | head -1)
echo "æ‰¾åˆ°æ¨¡å‹: $MODEL_PATH"
```

**Step 2**: è¿è¡Œæ¨ç†ç”Ÿæˆé‡å»ºå›¾ç‰‡

```bash
# ä½¿ç”¨ inference.py
python inference.py \
    --model_path "$MODEL_PATH" \
    --annotation_file /data/matrix-project/MiniDataset/stage1_annotations_500.json \
    --data_root /data/matrix-project/MiniDataset/data \
    --num_samples 10 \
    --output_dir evaluation/verification_after_fix \
    --output_format enhanced

echo ""
echo "âœ… é‡å»ºå®Œæˆï¼æŸ¥çœ‹ç»“æœ:"
echo "  ls -lh evaluation/verification_after_fix/"
```

**Step 3**: æŸ¥çœ‹ç”Ÿæˆçš„å›¾ç‰‡

```bash
# æŸ¥çœ‹è¾“å‡ºæ–‡ä»¶
ls -lh evaluation/verification_after_fix/

# ç”¨å›¾ç‰‡æŸ¥çœ‹å™¨æ‰“å¼€
# æˆ–è€…å¤åˆ¶åˆ°æœ¬åœ°æŸ¥çœ‹
```

**Step 4**: åˆ†æç»“æœ

```bash
# æŸ¥çœ‹æŒ‡æ ‡æ‘˜è¦
cat evaluation/verification_after_fix/inference_results.json | grep -A 5 "average"

# æœŸæœ›çœ‹åˆ°:
# "psnr": > 20  âœ…
# "ssim": > 0.6 âœ…
# "mse": < 0.01 âœ…
```

---

## ğŸ“Š ä¿®å¤å‰åå¯¹æ¯”å®éªŒï¼ˆå¯é€‰ï¼‰

å¦‚æœä½ æƒ³ç›´è§‚å¯¹æ¯”ä¿®å¤å‰åçš„æ•ˆæœï¼š

### Step 1: ä¿å­˜å½“å‰ï¼ˆä¿®å¤åï¼‰çš„ç»“æœ

```bash
# è¿è¡Œæ¨ç†
python inference.py \
    --model_path <æ¨¡å‹è·¯å¾„> \
    --annotation_file /data/matrix-project/MiniDataset/stage1_annotations_500.json \
    --data_root /data/matrix-project/MiniDataset/data \
    --num_samples 5 \
    --output_dir evaluation/after_fix

# ä¿å­˜æŒ‡æ ‡
cp evaluation/after_fix/inference_results.json evaluation/metrics_after_fix.json
```

### Step 2: ä¸´æ—¶æ¢å¤æ—§ä»£ç æµ‹è¯•ï¼ˆä»…ç”¨äºå¯¹æ¯”ï¼‰

**âš ï¸ è­¦å‘Š**: ä»…ç”¨äºå¯¹æ¯”å®éªŒï¼Œæµ‹è¯•å®Œç«‹å³æ”¹å›ï¼

```bash
# å¤‡ä»½ä¿®å¤åçš„ä»£ç 
cp inference.py inference.py.fixed

# ä¸´æ—¶æ¢å¤æ—§ä»£ç ï¼ˆæ‰‹åŠ¨ç¼–è¾‘ï¼‰
# åœ¨ inference.py 456è¡Œæ”¹ä¸º:
# frames = sample.unsqueeze(0).float() / 255.0  # æ¢å¤æ—§bug
```

### Step 3: è¿è¡Œå¯¹æ¯”æµ‹è¯•

```bash
# ç”¨æ—§ä»£ç è¿è¡Œï¼ˆåº”è¯¥ç”Ÿæˆå…¨é»‘å›¾åƒï¼‰
python inference.py \
    --model_path <æ¨¡å‹è·¯å¾„> \
    --annotation_file /data/matrix-project/MiniDataset/stage1_annotations_500.json \
    --data_root /data/matrix-project/MiniDataset/data \
    --num_samples 5 \
    --output_dir evaluation/before_fix

# ä¿å­˜æŒ‡æ ‡
cp evaluation/before_fix/inference_results.json evaluation/metrics_before_fix.json

# âš ï¸ ç«‹å³æ¢å¤ä¿®å¤åçš„ä»£ç ï¼
cp inference.py.fixed inference.py
```

### Step 4: å¯¹æ¯”ç»“æœ

```bash
# å¯¹æ¯”æŒ‡æ ‡
echo "ä¿®å¤å‰:"
cat evaluation/metrics_before_fix.json | grep -A 3 "average"

echo ""
echo "ä¿®å¤å:"
cat evaluation/metrics_after_fix.json | grep -A 3 "average"

# å¯¹æ¯”å›¾ç‰‡
ls -lh evaluation/before_fix/sample_000_reconstructed.mp4
ls -lh evaluation/after_fix/sample_000_reconstructed.mp4

# before_fix åº”è¯¥æ˜¯å…¨é»‘
# after_fix åº”è¯¥æœ‰æ­£å¸¸å†…å®¹
```

---

## ğŸ’¡ å®ç”¨å‘½ä»¤é€ŸæŸ¥

### å¿«é€ŸéªŒè¯æ•°æ®èŒƒå›´

```bash
# éªŒè¯ MiniDataset è¾“å‡ºï¼ˆ2åˆ†é’Ÿï¼‰
python scripts/check_dataset_output.py \
    --annotation_file /data/matrix-project/MiniDataset/stage1_annotations_500.json \
    --data_root /data/matrix-project/MiniDataset/data \
    --num_samples 3
```

### æŸ¥æ‰¾å¯ç”¨æ¨¡å‹

```bash
# æŸ¥æ‰¾æ‰€æœ‰æ¨¡å‹
find outputs -name "*.pth" -o -name "*.safetensors"

# æŸ¥æ‰¾æœ€æ–°æ¨¡å‹
ls -lt outputs/*/checkpoints/*.pth | head -1
```

### è¿è¡Œæ¨ç†ç”Ÿæˆå›¾ç‰‡

```bash
# æ›¿æ¢ <MODEL_PATH> ä¸ºå®é™…è·¯å¾„
python inference.py \
    --model_path <MODEL_PATH> \
    --annotation_file /data/matrix-project/MiniDataset/stage1_annotations_500.json \
    --data_root /data/matrix-project/MiniDataset/data \
    --num_samples 10 \
    --output_dir evaluation/test_results
```

### æŸ¥çœ‹ç»“æœ

```bash
# åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
ls -lh evaluation/test_results/

# æŸ¥çœ‹æŒ‡æ ‡
cat evaluation/test_results/inference_results.json

# æŸ¥çœ‹HTMLæŠ¥å‘Šï¼ˆå¦‚æœç”Ÿæˆäº†ï¼‰
# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ evaluation/test_results/inference_report.html
```

---

## ğŸ¯ å…³é”®è¦ç‚¹

### Inference.py çš„æ ¸å¿ƒ

1. **è¾“å…¥**: è§†é¢‘æ•°æ® + è®­ç»ƒå¥½çš„æ¨¡å‹
2. **å¤„ç†**: ç¼–ç  â†’ æ½œåœ¨è¡¨ç¤º â†’ è§£ç  â†’ é‡å»º
3. **è¾“å‡º**: é‡å»ºè§†é¢‘ + è´¨é‡æŒ‡æ ‡ + å¯è§†åŒ–

### ä¿®å¤éªŒè¯çš„å…³é”®

1. **æ•°æ®å±‚é¢**: MiniDataset è¾“å‡º [0, 1] âœ…
2. **æ¨¡å‹å±‚é¢**: æ¨ç†æ—¶ä¸å†é‡å¤å½’ä¸€åŒ– âœ…
3. **æ•ˆæœå±‚é¢**: é‡å»ºå›¾ç‰‡ä¸æ˜¯å…¨é»‘ âœ…

### è¯„ä¼°å·¥å…·é€‰æ‹©

| å·¥å…· | ç”¨é€” | æ—¶é—´ |
|------|------|------|
| `check_dataset_output.py` | éªŒè¯æ•°æ®èŒƒå›´ | 2åˆ†é’Ÿ |
| `inference.py` | ç”Ÿæˆé‡å»ºå›¾ç‰‡ | 5-10åˆ†é’Ÿ |
| `evaluate_vae.py` | å®Œæ•´æ¨¡å‹è¯„ä¼° | 10-30åˆ†é’Ÿ |
| `quick_evaluate.py` | ä¸€é”®å…¨é¢è¯„ä¼° | 20-40åˆ†é’Ÿ |

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- `CHANGES.md` - å˜æ›´æ—¥å¿—ä¸ä¿®å¤åˆå¹¶è®°å½•
- `TROUBLESHOOTING.md` - æ•…éšœæ’é™¤ï¼ˆç¯å¢ƒ/æ•°æ®/æ¨¡å‹ï¼‰
- `æ•°æ®èŒƒå›´æ£€æŸ¥ä½¿ç”¨æŒ‡å—.md` - æ•°æ®ä¸PSNRè¯Šæ–­

---

**ç°åœ¨ä½ å¯ä»¥å¼€å§‹éªŒè¯äº†ï¼** ğŸš€

å¦‚æœæ²¡æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå…ˆè®­ç»ƒä¸€ä¸ªï¼›å¦‚æœæœ‰æ¨¡å‹ï¼Œç›´æ¥è¿è¡Œ inference.py ç”Ÿæˆé‡å»ºå›¾ç‰‡éªŒè¯ä¿®å¤æ•ˆæœã€‚

