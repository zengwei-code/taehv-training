# TAEHVè®­ç»ƒé”™è¯¯æ’æŸ¥å’Œè§£å†³æŒ‡å—

æœ¬æ–‡æ¡£è®°å½•äº†TAEHVæ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°çš„æ‰€æœ‰é”™è¯¯é—®é¢˜ã€æ ¹æœ¬åŸå› åˆ†æå’Œè¯¦ç»†è§£å†³æ–¹æ³•ã€‚

## ğŸ“‹ ç›®å½•

1. [é”™è¯¯1: FileNotFoundError - Checkpointæ–‡ä»¶è·¯å¾„é—®é¢˜](#é”™è¯¯1-filenotfound-checkpointæ–‡ä»¶è·¯å¾„é—®é¢˜)
2. [é”™è¯¯2: DeepSpeed AssertionError - ä¼˜åŒ–å™¨ç¼ºå¤±é—®é¢˜](#é”™è¯¯2-deepspeed-assertionerror-ä¼˜åŒ–å™¨ç¼ºå¤±é—®é¢˜)
3. [é”™è¯¯3: TensorBoard ValueError - è¶…å‚æ•°ç±»å‹é—®é¢˜](#é”™è¯¯3-tensorboard-valueerror-è¶…å‚æ•°ç±»å‹é—®é¢˜)
4. [é”™è¯¯4: RuntimeError - æ··åˆç²¾åº¦ç±»å‹ä¸åŒ¹é…](#é”™è¯¯4-runtimeerror-æ··åˆç²¾åº¦ç±»å‹ä¸åŒ¹é…)
5. [é”™è¯¯5: NCCL DistBackendError - é€šä¿¡è¶…æ—¶é—®é¢˜](#é”™è¯¯5-nccl-distbackenderror-é€šä¿¡è¶…æ—¶é—®é¢˜)
6. [é”™è¯¯6: TypeError - isfinite()å‚æ•°ç±»å‹é—®é¢˜](#é”™è¯¯6-typeerror-isfiniteå‚æ•°ç±»å‹é—®é¢˜)
7. [é”™è¯¯7: Checkpointä¿å­˜é—®é¢˜ - ç©ºç›®å½•é—®é¢˜](#é”™è¯¯7-checkpointä¿å­˜é—®é¢˜-ç©ºç›®å½•é—®é¢˜)
8. [é”™è¯¯8: SIGTERMè¿›ç¨‹ç»ˆæ­¢é—®é¢˜](#é”™è¯¯8-sigtermè¿›ç¨‹ç»ˆæ­¢é—®é¢˜)
9. [é”™è¯¯9: Checkpointè·¯å¾„é€»è¾‘é”™è¯¯](#é”™è¯¯9-checkpointè·¯å¾„é€»è¾‘é”™è¯¯)
10. [é”™è¯¯10: Seraenaæ¨¡å‹DeepSpeedä¼˜åŒ–å™¨é—®é¢˜](#é”™è¯¯10-seraenaæ¨¡å‹deepspeedä¼˜åŒ–å™¨é—®é¢˜)
11. [é”™è¯¯11: Seraenaå¼ é‡å½¢çŠ¶ä¸åŒ¹é…é—®é¢˜](#é”™è¯¯11-seraenaå¼ é‡å½¢çŠ¶ä¸åŒ¹é…é—®é¢˜)
12. [é”™è¯¯12: TAEHVå¸§æ•°ç»´åº¦ä¸åŒ¹é… - decodedä¸frames_targetä¸ä¸€è‡´](#é”™è¯¯12-taehvå¸§æ•°ç»´åº¦ä¸åŒ¹é…-decodedä¸frames_targetä¸ä¸€è‡´)
13. [é”™è¯¯13: Seraenaå¸§æ•°ä¸èƒ½æ•´é™¤è­¦å‘Š - æ•°æ®æŸå¤±é—®é¢˜](#é”™è¯¯13-seraenaå¸§æ•°ä¸èƒ½æ•´é™¤è­¦å‘Š-æ•°æ®æŸå¤±é—®é¢˜)

---

## é”™è¯¯1: FileNotFoundError - Checkpointæ–‡ä»¶è·¯å¾„é—®é¢˜

### ğŸš¨ é”™è¯¯ç°è±¡
```bash
FileNotFoundError: [Errno 2] No such file or directory: '../checkpoints/taecvx.pth'
```

### ğŸ” æ ¹æœ¬åŸå› 
- é…ç½®æ–‡ä»¶ä¸­çš„`pretrained_model_path`ä½¿ç”¨äº†ç›¸å¯¹è·¯å¾„`../checkpoints/taecvx.pth`
- å®é™…æ‰§è¡Œæ—¶å·¥ä½œç›®å½•ä¸é¢„æœŸä¸ç¬¦ï¼Œå¯¼è‡´è·¯å¾„æ— æ³•æ‰¾åˆ°

### âœ… è§£å†³æ–¹æ³•

**ä¿®æ”¹æ–‡ä»¶**: `training/configs/taehv_config.py`

```python
# ä¿®æ”¹å‰
args.pretrained_model_path = "../checkpoints/taecvx.pth"

# ä¿®æ”¹å  
args.pretrained_model_path = "checkpoints/taecvx.pth"
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- ä½¿ç”¨ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
- æˆ–ä½¿ç”¨ç»å¯¹è·¯å¾„
- åœ¨è„šæœ¬ä¸­æ·»åŠ è·¯å¾„å­˜åœ¨æ€§æ£€æŸ¥

---

## é”™è¯¯2: DeepSpeed AssertionError - ä¼˜åŒ–å™¨ç¼ºå¤±é—®é¢˜

### ğŸš¨ é”™è¯¯ç°è±¡
```bash
AssertionError: zero stage 2 requires an optimizer
```

### ğŸ” æ ¹æœ¬åŸå› 
- `vae_ref`ï¼ˆå‚è€ƒVAEæ¨¡å‹ï¼‰è¢«é”™è¯¯åœ°ä¼ é€’ç»™`accelerator.prepare()`
- DeepSpeed ZeRO stage 2è¦æ±‚æ‰€æœ‰preparedçš„æ¨¡å‹éƒ½å¿…é¡»æœ‰å¯¹åº”çš„ä¼˜åŒ–å™¨
- ä½†`vae_ref`æ˜¯åªè¯»æ¨¡å‹ï¼Œä¸éœ€è¦è®­ç»ƒï¼Œå› æ­¤æ²¡æœ‰ä¼˜åŒ–å™¨

### âœ… è§£å†³æ–¹æ³•

**ä¿®æ”¹æ–‡ä»¶**: `training/taehv_train.py`

```python
# ä¿®æ”¹å‰
model, optimizer, train_dataloader, lr_scheduler, vae_ref = accelerator.prepare(
    model, optimizer, train_dataloader, lr_scheduler, vae_ref
)

# ä¿®æ”¹å
model, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(
    model, optimizer, train_dataloader, lr_scheduler
)

if vae_ref is not None:
    # å‚è€ƒVAEä¸éœ€è¦è®­ç»ƒï¼Œæ‰‹åŠ¨ç§»åŠ¨åˆ°è®¾å¤‡è€Œä¸æ˜¯é€šè¿‡DeepSpeedå‡†å¤‡
    vae_ref = vae_ref.to(accelerator.device)
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- åªå°†éœ€è¦è®­ç»ƒçš„æ¨¡å‹ä¼ é€’ç»™`accelerator.prepare()`
- å‚è€ƒæ¨¡å‹æ‰‹åŠ¨ç§»åŠ¨åˆ°è®¾å¤‡
- æ˜ç¡®åŒºåˆ†è®­ç»ƒæ¨¡å‹å’Œæ¨ç†æ¨¡å‹

---

## é”™è¯¯3: TensorBoard ValueError - è¶…å‚æ•°ç±»å‹é—®é¢˜

### ğŸš¨ é”™è¯¯ç°è±¡
```bash
ValueError: value should be one of int, float, str, bool, or torch.Tensor
```

### ğŸ” æ ¹æœ¬åŸå› 
- `accelerator.init_trackers()`åªæ”¯æŒç‰¹å®šæ•°æ®ç±»å‹çš„è¶…å‚æ•°
- é…ç½®å¯¹è±¡åŒ…å«ä¸æ”¯æŒçš„ç±»å‹ï¼Œå¦‚`datetime`å¯¹è±¡ã€å­—å…¸ç­‰

### âœ… è§£å†³æ–¹æ³•

**ä¿®æ”¹æ–‡ä»¶**: `training/taehv_train.py`

```python
# æ·»åŠ é…ç½®è¿‡æ»¤é€»è¾‘
if accelerator.is_main_process:
    # è¿‡æ»¤é…ç½®ï¼Œåªä¿ç•™TensorBoardæ”¯æŒçš„ç±»å‹
    filtered_config = {}
    for key, value in vars(config).items():
        if isinstance(value, (int, float, str, bool)) or (hasattr(value, 'dtype') and hasattr(value, 'device')):
            filtered_config[key] = value
        elif isinstance(value, dict):
            # å°†å­—å…¸è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            filtered_config[key] = str(value)
        else:
            # å°†å…¶ä»–ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            filtered_config[key] = str(value)
    
    accelerator.init_trackers(config.tracker_name, config=filtered_config)
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- å§‹ç»ˆè¿‡æ»¤é…ç½®å¯¹è±¡
- å°†å¤æ‚ç±»å‹è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¡¨ç¤º
- æµ‹è¯•ä¸åŒç±»å‹çš„é…ç½®å‚æ•°

---

## é”™è¯¯4: RuntimeError - æ··åˆç²¾åº¦ç±»å‹ä¸åŒ¹é…

### ğŸš¨ é”™è¯¯ç°è±¡
```bash
RuntimeError: Input type (float) and bias type (c10::BFloat16) should be the same
```

### ğŸ” æ ¹æœ¬åŸå› 
- æ··åˆç²¾åº¦è®­ç»ƒè®¾ç½®ä¸º`bf16`ï¼Œæ¨¡å‹å‚æ•°ä¸º`bfloat16`ç±»å‹
- è¾“å…¥æ•°æ®ä»ä¸º`float32`ç±»å‹
- åœ¨`accelerator.autocast()`å†…éƒ¨ç±»å‹è½¬æ¢ä¸ä¸€è‡´

### âœ… è§£å†³æ–¹æ³•

**ä¿®æ”¹æ–‡ä»¶**: `training/taehv_train.py`

```python
# ä¿®æ”¹å‰
with accelerator.autocast():
    frames = batch.float() / 255.0  # åœ¨autocastå†…éƒ¨è½¬æ¢

# ä¿®æ”¹å
# æ•°æ®é¢„å¤„ç† - æ˜ç¡®è½¬æ¢åˆ°æ­£ç¡®çš„è®¾å¤‡å’Œç±»å‹
frames = batch.float() / 255.0  # N,T,C,H,W, [0,1]
# è½¬æ¢åˆ°ä¸æ¨¡å‹å‚æ•°ç›¸åŒçš„ç±»å‹ï¼ˆbf16ï¼‰
frames = frames.to(accelerator.device, dtype=torch.bfloat16)

# å‰å‘ä¼ æ’­
with accelerator.autocast():
    # ç¼–ç 
    encoded = model.encode_video(frames, parallel=True, show_progress_bar=False)
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- åœ¨autocastå¤–éƒ¨è¿›è¡Œæ•°æ®ç±»å‹è½¬æ¢
- ç¡®ä¿è¾“å…¥æ•°æ®ç±»å‹ä¸æ¨¡å‹å‚æ•°ç±»å‹ä¸€è‡´
- æ˜¾å¼æŒ‡å®šè®¾å¤‡å’Œæ•°æ®ç±»å‹

---

## é”™è¯¯5: NCCL DistBackendError - é€šä¿¡è¶…æ—¶é—®é¢˜

### ğŸš¨ é”™è¯¯ç°è±¡
```bash
torch.distributed.DistBackendError: Watchdog caught collective operation timeout
```

### ğŸ” æ ¹æœ¬åŸå› 
- NCCLé€šä¿¡è¶…æ—¶ï¼Œå¯èƒ½ç”±ä»¥ä¸‹åŸå› å¼•èµ·ï¼š
  - æ‰¹é‡å¤§å°è¿‡å¤§å¯¼è‡´å†…å­˜å‹åŠ›
  - ç½‘ç»œé€šä¿¡ä¸ç¨³å®š
  - æ¢¯åº¦åŒæ­¥æ—¶é—´è¿‡é•¿
  - GPUé—´é€šä¿¡å»¶è¿Ÿ

### âœ… è§£å†³æ–¹æ³•

#### æ–¹æ³•1: è°ƒæ•´æ‰¹é‡å¤§å°å’Œæ¢¯åº¦ç´¯ç§¯

**ä¿®æ”¹æ–‡ä»¶**: `training/configs/taehv_config.py`

```python
# å‡å°‘æ‰¹é‡å¤§å°ï¼Œå¢åŠ æ¢¯åº¦ç´¯ç§¯æ­¥æ•°
args.train_batch_size = 2  # ä»4å‡å°‘åˆ°2
args.gradient_accumulation_steps = 2  # ä»1å¢åŠ åˆ°2
```

#### æ–¹æ³•2: ä¼˜åŒ–DeepSpeedé…ç½®

**ä¿®æ”¹æ–‡ä»¶**: `accelerate_configs/deepspeed.yaml`

```yaml
deepspeed_config:
  deepspeed_multinode_launcher: standard
  gradient_accumulation_steps: 1
  offload_optimizer_device: cpu
  offload_param_device: cpu
  zero3_init_flag: false
  zero_stage: 2
  communication_data_type: fp16  # æ–°å¢ï¼šä½¿ç”¨fp16é€šä¿¡
  allgather_bucket_size: 50000000  # æ–°å¢ï¼šä¼˜åŒ–é€šä¿¡æ¡¶å¤§å°
  reduce_bucket_size: 50000000    # æ–°å¢ï¼šä¼˜åŒ–reduceæ¡¶å¤§å°
  overlap_comm: true              # æ–°å¢ï¼šé‡å é€šä¿¡å’Œè®¡ç®—
  contiguous_gradients: true      # æ–°å¢ï¼šä½¿ç”¨è¿ç»­æ¢¯åº¦
```

#### æ–¹æ³•3: ä¼˜åŒ–NCCLç¯å¢ƒå˜é‡

**ä¿®æ”¹æ–‡ä»¶**: `train_taehv.sh`

```bash
# NCCLä¼˜åŒ–ç¯å¢ƒå˜é‡
export NCCL_P2P_DISABLE=1                    # ç¦ç”¨P2Pï¼Œä½¿ç”¨æ›´ç¨³å®šçš„é€šä¿¡æ–¹å¼
export NCCL_TIMEOUT=7200                     # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°2å°æ—¶
export NCCL_BLOCKING_WAIT=1                  # å¯ç”¨é˜»å¡ç­‰å¾…
export NCCL_IB_DISABLE=1                     # ç¦ç”¨InfiniBandï¼ˆå¦‚æœæœ‰ç½‘ç»œé—®é¢˜ï¼‰
export NCCL_SOCKET_NTHREADS=4               # å¢åŠ socketçº¿ç¨‹æ•°
export NCCL_NSOCKS_PERTHREAD=8              # å¢åŠ æ¯çº¿ç¨‹socketæ•°
export NCCL_BUFFSIZE=8388608                # å¢åŠ ç¼“å†²åŒºå¤§å°(8MB)
export NCCL_NET_GDR_LEVEL=5                 # ä¼˜åŒ–GPU Direct RDMA
export NCCL_DEBUG=INFO                       # å¯ç”¨è°ƒè¯•ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰

# PyTorchåˆ†å¸ƒå¼ä¼˜åŒ–
export TORCH_NCCL_ENABLE_MONITORING=0       # ç¦ç”¨NCCLç›‘æ§å‡å°‘å¼€é”€
export TORCH_NCCL_BLOCKING_WAIT=1           # PyTorchå±‚é¢çš„é˜»å¡ç­‰å¾…
export TORCH_DISTRIBUTED_DEBUG=INFO         # å¯ç”¨åˆ†å¸ƒå¼è°ƒè¯•ä¿¡æ¯
```

#### æ–¹æ³•4: æ·»åŠ é”™è¯¯å¤„ç†å’Œå†…å­˜ç®¡ç†

**ä¿®æ”¹æ–‡ä»¶**: `training/taehv_train.py`

```python
# æ·»åŠ NaNæ£€æŸ¥å’Œé”™è¯¯å¤„ç†
if not torch.isfinite(total_loss):
    logger.warning(f"Loss is not finite: {total_loss}, skipping step")
    optimizer.zero_grad()
    continue

try:
    accelerator.backward(total_loss)
    
    if accelerator.sync_gradients:
        # æ¡ä»¶æ€§æ¢¯åº¦è£å‰ªï¼ˆDeepSpeedè‡ªåŠ¨å¤„ç†ï¼‰
        if accelerator.distributed_type != DistributedType.DEEPSPEED:
            grad_norm = accelerator.clip_grad_norm_(model.parameters(), config.max_grad_norm)
            if not math.isfinite(grad_norm):
                logger.warning(f"Gradient norm is not finite: {grad_norm}, skipping step")
                optimizer.zero_grad()
                continue
                
except RuntimeError as e:
    if "out of memory" in str(e):
        logger.error(f"GPU OOM at step {global_step}, skipping batch")
        torch.cuda.empty_cache()
        optimizer.zero_grad()
        continue
    else:
        raise e

# å®šæœŸå†…å­˜æ¸…ç†
if global_step % 100 == 0:
    torch.cuda.empty_cache()
    if hasattr(accelerator.state, 'deepspeed_plugin') and accelerator.state.deepspeed_plugin is not None:
        import gc
        gc.collect()
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- ç›‘æ§GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
- å®šæœŸæ¸…ç†å†…å­˜ç¢ç‰‡
- ä½¿ç”¨æ›´ä¿å®ˆçš„æ‰¹é‡å¤§å°
- å¢åŠ NCCLè¶…æ—¶æ—¶é—´
- å¯ç”¨é€šä¿¡è°ƒè¯•ä¿¡æ¯

---

## é”™è¯¯6: TypeError - isfinite()å‚æ•°ç±»å‹é—®é¢˜

### ğŸš¨ é”™è¯¯ç°è±¡
```bash
TypeError: isfinite(): argument 'input' (position 1) must be Tensor, not float
```

### ğŸ” æ ¹æœ¬åŸå› 
- `accelerator.clip_grad_norm_()`è¿”å›Python floatç±»å‹çš„æ¢¯åº¦èŒƒæ•°
- `torch.isfinite()`åªæ¥å—torch.Tensorç±»å‹å‚æ•°
- éœ€è¦ä½¿ç”¨`math.isfinite()`å¤„ç†Python float

### âœ… è§£å†³æ–¹æ³•

**ä¿®æ”¹æ–‡ä»¶**: `training/taehv_train.py`

```python
# ä¿®æ”¹å‰
grad_norm = accelerator.clip_grad_norm_(model.parameters(), config.max_grad_norm)
if not torch.isfinite(grad_norm):  # é”™è¯¯ï¼šgrad_normæ˜¯Python float
    logger.warning(f"Gradient norm is not finite: {grad_norm}, skipping step")

# ä¿®æ”¹å
import math  # ç¡®ä¿å¯¼å…¥mathæ¨¡å—

grad_norm = accelerator.clip_grad_norm_(model.parameters(), config.max_grad_norm)
if not math.isfinite(grad_norm):  # æ­£ç¡®ï¼šä½¿ç”¨math.isfiniteå¤„ç†Python float
    logger.warning(f"Gradient norm is not finite: {grad_norm}, skipping step")
    optimizer.zero_grad()
    continue
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- åŒºåˆ†torch.Tensorå’ŒPythonåŸºç¡€ç±»å‹
- å¯¹torch.Tensorä½¿ç”¨`torch.isfinite()`
- å¯¹Python floatä½¿ç”¨`math.isfinite()`
- æ·»åŠ ç±»å‹æ£€æŸ¥å’Œæµ‹è¯•

---

## é”™è¯¯7: Checkpointä¿å­˜é—®é¢˜ - ç©ºç›®å½•é—®é¢˜

### ğŸš¨ é”™è¯¯ç°è±¡
- Checkpointç›®å½•è¢«åˆ›å»ºä½†å®Œå…¨ä¸ºç©º
- `ls checkpoint-500/` æ˜¾ç¤ºæ²¡æœ‰ä»»ä½•æ–‡ä»¶

### ğŸ” æ ¹æœ¬åŸå› 
1. `accelerator.save_state()`è¢«é”™è¯¯åœ°åŒ…è£…åœ¨ä¸»è¿›ç¨‹æ¡ä»¶ä¸­
2. ç¼ºå°‘æ¨¡å‹åºåˆ—åŒ–hooks
3. `accelerator.save_state()`å†…éƒ¨å·²å¤„ç†å¤šè¿›ç¨‹åè°ƒï¼Œä¸éœ€è¦é¢å¤–æ¡ä»¶

### âœ… è§£å†³æ–¹æ³•

#### æ–¹æ³•1: æ·»åŠ ä¿å­˜hooks

**ä¿®æ”¹æ–‡ä»¶**: `training/taehv_train.py`

```python
# åœ¨accelerator.prepare()ä¹‹åæ·»åŠ 
def save_model_hook(models, weights, output_dir):
    if accelerator.is_main_process:
        # ä¿å­˜ä¸»æ¨¡å‹çŠ¶æ€
        model_to_save = accelerator.unwrap_model(model)
        torch.save(model_to_save.state_dict(), os.path.join(output_dir, "model.pth"))
        logger.info(f"Saved model state dict to {output_dir}/model.pth")

def load_model_hook(models, input_dir):
    # æ¨¡å‹åŠ è½½é€»è¾‘ï¼ˆå¦‚æœéœ€è¦ï¼‰
    pass

# æ³¨å†Œhooks
accelerator.register_save_state_pre_hook(save_model_hook)
accelerator.register_load_state_pre_hook(load_model_hook)
```

#### æ–¹æ³•2: ä¿®æ­£ä¿å­˜é€»è¾‘

```python
# ä¿®æ”¹å‰
if accelerator.is_main_process:
    try:
        save_path = os.path.join(config.output_dir, f"checkpoint-{global_step}")
        accelerator.save_state(save_path)  # é”™è¯¯ï¼šåœ¨ä¸»è¿›ç¨‹æ¡ä»¶å†…

# ä¿®æ”¹å
try:
    # accelerator.save_state()å†…éƒ¨å¤„ç†å¤šè¿›ç¨‹åè°ƒ
    save_path = os.path.join(config.output_dir, f"checkpoint-{global_step}")
    accelerator.save_state(save_path)
    if accelerator.is_main_process:
        logger.info(f"âœ… Successfully saved checkpoint to {save_path}")
```

#### æ–¹æ³•3: æ·»åŠ å¿…è¦å¯¼å…¥

```python
import shutil  # ç”¨äºcheckpointæ¸…ç†åŠŸèƒ½
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- æ€»æ˜¯æ³¨å†Œsave/load hooks
- ç†è§£accelerator.save_state()çš„å¤šè¿›ç¨‹è¡Œä¸º
- éªŒè¯ä¿å­˜çš„checkpointå†…å®¹
- æ·»åŠ ä¿å­˜å¤±è´¥çš„é”™è¯¯å¤„ç†

---

## é”™è¯¯8: SIGTERMè¿›ç¨‹ç»ˆæ­¢é—®é¢˜

### ğŸš¨ é”™è¯¯ç°è±¡
```bash
Signal 15 (SIGTERM) received by PID 2766193
torch.distributed.elastic.multiprocessing.errors.ChildFailedError
```

### ğŸ” æ ¹æœ¬åŸå› 
- **SIGTERM (ä¿¡å·15)** = å¤–éƒ¨å¼ºåˆ¶ç»ˆæ­¢
- ä¸æ˜¯ä»£ç é”™è¯¯ï¼Œè€Œæ˜¯ç³»ç»Ÿçº§åˆ«çš„è¿›ç¨‹ç®¡ç†
- å¯èƒ½åŸå› ï¼š
  - ç”¨æˆ·æ‰‹åŠ¨åœæ­¢ï¼ˆCtrl+Cï¼‰
  - ç³»ç»Ÿèµ„æºé™åˆ¶
  - ä½œä¸šè°ƒåº¦å™¨ç»ˆæ­¢
  - ç½‘ç»œè¿æ¥ä¸­æ–­
  - ç³»ç»Ÿç»´æŠ¤/é‡å¯

### âœ… è§£å†³æ–¹æ³•

#### æ–¹æ³•1: ä»checkpointæ¢å¤ï¼ˆæ¨èï¼‰

**ä¿®æ”¹æ–‡ä»¶**: `training/configs/taehv_config.py`

```python
# è®¾ç½®æ¢å¤è·¯å¾„åˆ°æœ€æ–°checkpoint
args.resume_from_checkpoint = "output/2025-09-29_22-24-51/checkpoint-5500"
```

ç„¶åæ­£å¸¸å¯åŠ¨ï¼š
```bash
bash train_taehv.sh
```

#### æ–¹æ³•2: è‡ªåŠ¨æ¢å¤è„šæœ¬

åˆ›å»º `auto_recovery_train.sh`ï¼š

```bash
#!/bin/bash

while true; do
    echo "Starting/Resuming training..."
    bash train_taehv.sh
    
    exit_code=$?
    if [ $exit_code -eq 0 ]; then
        echo "âœ… Training completed successfully!"
        break
    else
        echo "âŒ Training interrupted (exit code: $exit_code)"
        echo "Will restart in 10 seconds..."
        sleep 10
        
        # è‡ªåŠ¨æ‰¾åˆ°æœ€æ–°checkpointå¹¶æ›´æ–°é…ç½®
        latest_checkpoint=$(find output/ -name "checkpoint-*" -type d | sort -V | tail -1)
        if [ ! -z "$latest_checkpoint" ]; then
            echo "Found latest checkpoint: $latest_checkpoint"
            sed -i "s|args.resume_from_checkpoint = .*|args.resume_from_checkpoint = \"$latest_checkpoint\"|" training/configs/taehv_config.py
        fi
    fi
done
```

#### æ–¹æ³•3: å¢å¼ºç›‘æ§å’Œæ—¥å¿—

```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ ä¿¡å·å¤„ç†
import signal
import sys

def signal_handler(sig, frame):
    logger.info(f"Received signal {sig}, saving checkpoint and exiting...")
    # å¼ºåˆ¶ä¿å­˜checkpoint
    if 'global_step' in locals():
        save_path = os.path.join(config.output_dir, f"emergency_checkpoint-{global_step}")
        accelerator.save_state(save_path)
        logger.info(f"Emergency checkpoint saved to {save_path}")
    sys.exit(0)

signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- é¢‘ç¹ä¿å­˜checkpointï¼ˆæ¯500æ­¥ï¼‰
- ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨
- ä½¿ç”¨ä½œä¸šè°ƒåº¦å™¨çš„æ£€æŸ¥ç‚¹æœºåˆ¶
- è®¾ç½®åˆç†çš„ä½œä¸šæ—¶é—´é™åˆ¶
- æ·»åŠ è®­ç»ƒè¿›åº¦ç›‘æ§å’Œå‘Šè­¦

---

## ğŸ¯ æ€»ç»“å’Œæœ€ä½³å®è·µ

### âœ… æˆåŠŸè§£å†³çš„é—®é¢˜
1. **æ–‡ä»¶è·¯å¾„é—®é¢˜** â†’ ä½¿ç”¨é¡¹ç›®ç›¸å¯¹è·¯å¾„
2. **DeepSpeedé…ç½®** â†’ æ­£ç¡®åˆ†ç¦»è®­ç»ƒå’Œæ¨ç†æ¨¡å‹
3. **ç±»å‹å…¼å®¹æ€§** â†’ æ·»åŠ ç±»å‹è¿‡æ»¤å’Œè½¬æ¢
4. **æ··åˆç²¾åº¦** â†’ æ˜¾å¼ç±»å‹è½¬æ¢
5. **é€šä¿¡è¶…æ—¶** â†’ å¤šå±‚æ¬¡ä¼˜åŒ–ï¼ˆæ‰¹é‡å¤§å°ã€NCCLã€DeepSpeedï¼‰
6. **æ¢¯åº¦æ£€æŸ¥** â†’ åŒºåˆ†Tensorå’ŒPythonç±»å‹
7. **Checkpointä¿å­˜** â†’ æ·»åŠ hookså’Œä¿®æ­£ä¿å­˜é€»è¾‘
8. **è¿›ç¨‹ç®¡ç†** â†’ å®ç°æ¢å¤æœºåˆ¶
9. **Checkpointè·¯å¾„é€»è¾‘** â†’ æ”¯æŒå®Œæ•´è·¯å¾„å’Œç›¸å¯¹è·¯å¾„
10. **Seraenaæ¨¡å‹é…ç½®** â†’ åŒºåˆ†è®­ç»ƒå’Œæ¨ç†æ¨¡å‹
11. **å¼ é‡å½¢çŠ¶ä¸åŒ¹é…** â†’ é‡æ–°è®¾è®¡å¯¹ç§°å‡½æ•°å’Œå½¢çŠ¶ä¿¡æ¯ä¼ é€’

### ğŸ›¡ï¸ å…³é”®é¢„é˜²æªæ–½
1. **è·¯å¾„ç®¡ç†**ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„æˆ–é¡¹ç›®ç›¸å¯¹è·¯å¾„
2. **ç±»å‹å®‰å…¨**ï¼šæ˜¾å¼ç±»å‹è½¬æ¢å’Œæ£€æŸ¥
3. **é”™è¯¯å¤„ç†**ï¼šå…¨é¢çš„å¼‚å¸¸æ•è·å’Œæ¢å¤é€»è¾‘
4. **èµ„æºç®¡ç†**ï¼šå®šæœŸå†…å­˜æ¸…ç†å’Œç›‘æ§
5. **æ£€æŸ¥ç‚¹ç­–ç•¥**ï¼šé¢‘ç¹ä¿å­˜å’ŒéªŒè¯checkpointå®Œæ•´æ€§
6. **é€šä¿¡ä¼˜åŒ–**ï¼šåˆç†çš„è¶…æ—¶å’Œç¼“å†²åŒºé…ç½®
7. **ç›‘æ§å‘Šè­¦**ï¼šå®æ—¶ç›‘æ§è®­ç»ƒçŠ¶æ€å’Œèµ„æºä½¿ç”¨
8. **DeepSpeedé…ç½®**ï¼šæ˜ç¡®åŒºåˆ†è®­ç»ƒå’Œæ¨ç†æ¨¡å‹ï¼Œé¿å…æ— ä¼˜åŒ–å™¨çš„æ¨¡å‹ä¼ å…¥`accelerator.prepare()`
9. **å¼ é‡ç»´åº¦è®¾è®¡**ï¼šç¡®ä¿ç»´åº¦å˜æ¢å‡½æ•°å¯¹ç§°è®¾è®¡ï¼Œä¼ é€’å¿…è¦çš„å½¢çŠ¶ä¿¡æ¯
10. **è¾¹ç•Œæ¡ä»¶å¤„ç†**ï¼šæ™ºèƒ½å¤„ç†å¸§æ•°ä¸æ•´é™¤ç­‰è¾¹ç•Œæƒ…å†µï¼Œè€Œéç®€å•è·³è¿‡

### ğŸš€ è®­ç»ƒç¨³å®šæ€§å»ºè®®
1. ä½¿ç”¨ä¿å®ˆçš„æ‰¹é‡å¤§å°è®¾ç½®
2. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜
3. è®¾ç½®åˆç†çš„NCCLè¶…æ—¶æ—¶é—´
4. å®šæœŸéªŒè¯checkpointå®Œæ•´æ€§
5. ç›‘æ§GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
6. å®ç°è‡ªåŠ¨æ¢å¤æœºåˆ¶

---

## é”™è¯¯9: Checkpointè·¯å¾„é€»è¾‘é”™è¯¯

### ğŸš¨ é”™è¯¯ç°è±¡
```bash
ValueError: Tried to find output/2025-09-30_12-38-46/checkpoint-5500 but folder does not exist
```

### ğŸ” æ ¹æœ¬åŸå› 
- é…ç½®ä¸­è®¾ç½®äº†å®Œæ•´çš„checkpointè·¯å¾„ï¼š`"output/2025-09-29_22-24-51/checkpoint-5500"`
- ä½†ç¨‹åºå¯åŠ¨æ—¶åˆ›å»ºäº†æ–°çš„æ—¶é—´æˆ³è¾“å‡ºç›®å½•ï¼š`output/2025-09-30_12-38-46/`
- ä»£ç é€»è¾‘é”™è¯¯ï¼šæå–äº†checkpointåç§°`checkpoint-5500`ï¼Œç„¶åä¸æ–°ç›®å½•ç»„åˆ
- ç»“æœå¯»æ‰¾é”™è¯¯è·¯å¾„ï¼š`output/2025-09-30_12-38-46/checkpoint-5500`ï¼ˆå®é™…ä¸å­˜åœ¨ï¼‰

### âœ… è§£å†³æ–¹æ³•

**ä¿®æ”¹æ–‡ä»¶**: `training/taehv_train.py`

```python
# ä¿®æ”¹å‰çš„é”™è¯¯é€»è¾‘
if config.resume_from_checkpoint != "latest":
    path = os.path.basename(config.resume_from_checkpoint)  # åªæå–checkpointåç§°
    # ç„¶åé”™è¯¯åœ°ä¸æ–°ç›®å½•ç»„åˆ
    accelerator.load_state(os.path.join(config.output_dir, path))

# ä¿®æ”¹åçš„æ­£ç¡®é€»è¾‘
if config.resume_from_checkpoint != "latest":
    # æ£€æŸ¥æ˜¯å¦ä¸ºå®Œæ•´è·¯å¾„ï¼ˆåŒ…å«è·¯å¾„åˆ†éš”ç¬¦ï¼‰
    if os.path.sep in config.resume_from_checkpoint or '/' in config.resume_from_checkpoint:
        # å®Œæ•´è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨
        checkpoint_path = config.resume_from_checkpoint
        path = os.path.basename(config.resume_from_checkpoint)  # ç”¨äºæå–æ­¥æ•°
    else:
        # åªæ˜¯checkpointåç§°ï¼Œéœ€è¦ç»„åˆè·¯å¾„
        path = config.resume_from_checkpoint
        checkpoint_path = os.path.join(config.output_dir, path)
else:
    # è·å–æœ€æ–°çš„æ£€æŸ¥ç‚¹
    dirs = os.listdir(config.output_dir)
    dirs = [d for d in dirs if d.startswith("checkpoint")]
    dirs = sorted(dirs, key=lambda x: int(x.split("-")[1]))
    path = dirs[-1] if len(dirs) > 0 else None
    checkpoint_path = os.path.join(config.output_dir, path) if path else None

# æ£€æŸ¥checkpointæ˜¯å¦å­˜åœ¨
if path is None or not os.path.exists(checkpoint_path):
    accelerator.print(
        f"Checkpoint '{config.resume_from_checkpoint}' does not exist. Starting a new training run."
    )
    config.resume_from_checkpoint = None
    initial_global_step = 0
else:
    accelerator.print(f"Resuming from checkpoint {path}")
    accelerator.load_state(checkpoint_path)  # ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„
    global_step = int(path.split("-")[1])
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- åŒºåˆ†å®Œæ•´è·¯å¾„å’Œç›¸å¯¹è·¯å¾„
- æ·»åŠ è·¯å¾„å­˜åœ¨æ€§æ£€æŸ¥
- æ”¯æŒå¤šç§checkpointæŒ‡å®šæ–¹å¼ï¼š
  - å®Œæ•´è·¯å¾„ï¼š`"output/2025-09-29_22-24-51/checkpoint-5500"`
  - ç›¸å¯¹åç§°ï¼š`"checkpoint-5500"`
  - æœ€æ–°ï¼š`"latest"`

### ğŸ’¡ **ä½¿ç”¨å»ºè®®**
```python
# æ¨èçš„checkpointé…ç½®æ–¹å¼
args.resume_from_checkpoint = "output/2025-09-29_22-24-51/checkpoint-5500"  # å®Œæ•´è·¯å¾„
# æˆ–
args.resume_from_checkpoint = "latest"  # è‡ªåŠ¨æ‰¾æœ€æ–°çš„
# æˆ–
args.resume_from_checkpoint = "checkpoint-5500"  # å½“å‰è¾“å‡ºç›®å½•ä¸‹çš„checkpoint
```

---

## é”™è¯¯10: Seraenaæ¨¡å‹DeepSpeedä¼˜åŒ–å™¨é—®é¢˜

### ğŸš¨ é”™è¯¯ç°è±¡
```bash
AssertionError: zero stage 2 requires an optimizer
File "training/taehv_train.py", line 220, in main
  seraena = accelerator.prepare(seraena)
```

### ğŸ” æ ¹æœ¬åŸå› 
- `seraena`æ¨¡å‹ï¼ˆå¯¹æŠ—è®­ç»ƒæ¨¡å—ï¼‰è¢«ä¼ é€’ç»™`accelerator.prepare()`
- ä½†`seraena`æ²¡æœ‰å¯¹åº”çš„ä¼˜åŒ–å™¨
- DeepSpeed ZeRO stage 2è¦æ±‚æ‰€æœ‰preparedçš„æ¨¡å‹éƒ½å¿…é¡»æœ‰å¯¹åº”çš„ä¼˜åŒ–å™¨
- è¿™å’Œé”™è¯¯2ä¸­çš„`vae_ref`é—®é¢˜å®Œå…¨ç›¸åŒ

### âœ… è§£å†³æ–¹æ³•

**ä¿®æ”¹æ–‡ä»¶**: `training/taehv_train.py`

```python
# ä¿®æ”¹å‰
if seraena is not None:
    seraena = accelerator.prepare(seraena)  # é”™è¯¯ï¼šæ²¡æœ‰ä¼˜åŒ–å™¨

# ä¿®æ”¹å
if seraena is not None:
    # Seraenaä¸éœ€è¦è®­ç»ƒï¼Œæ‰‹åŠ¨ç§»åŠ¨åˆ°è®¾å¤‡è€Œä¸æ˜¯é€šè¿‡DeepSpeedå‡†å¤‡
    seraena = seraena.to(accelerator.device)
```

### ğŸ” **é—®é¢˜æ¨¡å¼è¯†åˆ«**

è¿™æ˜¯DeepSpeedé…ç½®çš„**ç»å…¸é—®é¢˜æ¨¡å¼**ï¼š
1. âŒ **é”™è¯¯2**: `vae_ref`æ¨¡å‹æ²¡æœ‰ä¼˜åŒ–å™¨
2. âŒ **é”™è¯¯10**: `seraena`æ¨¡å‹æ²¡æœ‰ä¼˜åŒ–å™¨

**é€šç”¨è§„åˆ™**ï¼š
- âœ… **è®­ç»ƒæ¨¡å‹** â†’ `accelerator.prepare(model, optimizer, ...)`
- âœ… **æ¨ç†æ¨¡å‹** â†’ `model.to(accelerator.device)`

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- æ˜ç¡®åŒºåˆ†**è®­ç»ƒæ¨¡å‹**å’Œ**æ¨ç†æ¨¡å‹**
- åªæœ‰éœ€è¦æ¢¯åº¦æ›´æ–°çš„æ¨¡å‹æ‰é€šè¿‡`accelerator.prepare()`
- å‚è€ƒæ¨¡å‹/è¾…åŠ©æ¨¡å‹æ‰‹åŠ¨ç§»åŠ¨åˆ°è®¾å¤‡
- æ£€æŸ¥æ‰€æœ‰`accelerator.prepare()`è°ƒç”¨æ˜¯å¦æœ‰å¯¹åº”çš„ä¼˜åŒ–å™¨

### ğŸ’¡ **è¯†åˆ«æ–¹æ³•**
```python
# âœ… æ­£ç¡®ï¼šä¸»è®­ç»ƒæ¨¡å‹
model, optimizer, dataloader = accelerator.prepare(model, optimizer, dataloader)

# âŒ é”™è¯¯ï¼šæ²¡æœ‰ä¼˜åŒ–å™¨çš„æ¨¡å‹
auxiliary_model = accelerator.prepare(auxiliary_model)  # ç¼ºå°‘ä¼˜åŒ–å™¨

# âœ… æ­£ç¡®ï¼šè¾…åŠ©æ¨¡å‹
auxiliary_model = auxiliary_model.to(accelerator.device)
```

---

## é”™è¯¯11: Seraenaå¼ é‡å½¢çŠ¶ä¸åŒ¹é…é—®é¢˜

### ğŸš¨ é”™è¯¯ç°è±¡
```bash
Seraena training failed: shape '[-1, 15, 3, 128, 128]' is invalid for input of size 1179648, skipping adversarial loss
```

### ğŸ” æ ¹æœ¬åŸå› 
- **æ ¸å¿ƒé—®é¢˜**ï¼š`pad_and_group` å’Œ `ungroup_and_unpad` å‡½æ•°è®¾è®¡ä¸å¯¹ç§°
- **ç»´åº¦ä¿¡æ¯ä¸¢å¤±**ï¼šåœ¨å¼ é‡å˜æ¢è¿‡ç¨‹ä¸­ï¼ŒåŸå§‹å½¢çŠ¶ä¿¡æ¯æ²¡æœ‰è¢«æ­£ç¡®ä¼ é€’
- **å…·ä½“è¡¨ç°**ï¼šæœŸæœ›å½¢çŠ¶ `[-1, 15, 3, 128, 128]` vs å®é™…è¾“å…¥ `[8, 9, 128, 128]`
- **æ•°å­¦ä¸åŒ¹é…**ï¼š`1,179,648 â‰  batch Ã— 737,280`ï¼ˆæ¯”ä¾‹1.60ä¸æ˜¯æ•´æ•°ï¼‰
- **è®¾è®¡ç¼ºé™·**ï¼š`ungroup_and_unpad` è¯•å›¾ä»è¾“å‡ºæ¨æ–­åŸå§‹ç»´åº¦ï¼Œä½†ä¿¡æ¯ä¸è¶³

### ğŸ“Š **æ•°å€¼åˆ†æ**
```python
# é…ç½®å‚æ•°
config.n_frames = 12           # æ¯ä¸ªæ ·æœ¬çš„å¸§æ•°
config.n_seraena_frames = 3    # Seraenaåˆ†ç»„çš„å¸§æ•°
model.frames_to_trim = 3       # éœ€è¦ä¿®å‰ªçš„å¸§æ•°

# æœŸæœ›è®¡ç®—
total_frames = 12 + 3 = 15
expected_elements = batch Ã— 15 Ã— 3 Ã— 128 Ã— 128 = batch Ã— 737,280

# å®é™…æƒ…å†µ
actual_elements = 1,179,648 â‰ˆ batch Ã— 1.6 Ã— 737,280 (ä¸åŒ¹é…)
```

### âœ… è§£å†³æ–¹æ³•

**ä¿®æ”¹æ–‡ä»¶**: `training/taehv_train.py`

**é—®é¢˜æ ¹æº**ï¼š`pad_and_group` å’Œ `ungroup_and_unpad` å‡½æ•°ä¸å¯¹ç§°ï¼Œå¯¼è‡´ç»´åº¦ä¿¡æ¯ä¸¢å¤±ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šé‡æ–°è®¾è®¡å‡½æ•°ä½¿å…¶å®Œå…¨å¯¹ç§°ï¼Œå¹¶ä¼ é€’åŸå§‹å½¢çŠ¶ä¿¡æ¯ã€‚

```python
# 1. å¢å¼º pad_and_group å‡½æ•°ï¼Œæ·»åŠ è°ƒè¯•å’Œå®¹é”™
def pad_and_group(x):
    logger.debug(f"pad_and_group input shape: {x.shape}")
    
    frames_to_trim = getattr(model, 'frames_to_trim', 0)
    logger.debug(f"frames_to_trim: {frames_to_trim}")
    
    if frames_to_trim > 0:
        x_padded = torch.cat([x, x[:, :frames_to_trim]], 1)
    else:
        x_padded = x
        
    n, t, c, h, w = x_padded.shape
    logger.debug(f"After padding: {x_padded.shape}")
    
    # ç¡®ä¿å¸§æ•°èƒ½è¢«n_seraena_framesæ•´é™¤
    if t % config.n_seraena_frames != 0:
        logger.warning(f"Frame count {t} is not divisible by n_seraena_frames {config.n_seraena_frames}")
        t_trimmed = (t // config.n_seraena_frames) * config.n_seraena_frames
        x_padded = x_padded[:, :t_trimmed]
        t = t_trimmed
    
    result = x_padded.reshape(n * t//config.n_seraena_frames, config.n_seraena_frames*c, h, w)
    return result

# 2. é‡æ–°è®¾è®¡ ungroup_and_unpad å‡½æ•°ï¼Œæ¥å—åŸå§‹å½¢çŠ¶ä¿¡æ¯
def ungroup_and_unpad(x, original_shape):
    """
    å°†pad_and_groupçš„è¾“å‡ºè½¬æ¢å›åŸå§‹æ ¼å¼
    x: [n_groups, grouped_c, h, w] - pad_and_groupçš„è¾“å‡º
    original_shape: [N, T, C, H, W] - åŸå§‹å¼ é‡çš„å½¢çŠ¶
    """
    n_groups, grouped_c, h, w = x.shape
    original_n, original_t, original_c, original_h, original_w = original_shape
    
    c = grouped_c // config.n_seraena_frames
    frames_to_trim = getattr(model, 'frames_to_trim', 0)
    
    # è®¡ç®—å®é™…çš„å¤„ç†å¸§æ•°
    padded_frames = original_t + (frames_to_trim if frames_to_trim > 0 else 0)
    actual_frames = (padded_frames // config.n_seraena_frames) * config.n_seraena_frames
    
    # éªŒè¯ç»´åº¦ä¸€è‡´æ€§
    expected_n_groups = original_n * actual_frames // config.n_seraena_frames
    if n_groups != expected_n_groups:
        logger.warning(f"Group count mismatch: got {n_groups}, expected {expected_n_groups}")
        return None
    
    # reshapeå›åŸå§‹æ ¼å¼
    x_ungrouped = x.reshape(original_n, actual_frames, c, h, w)
    
    # å»æ‰paddingçš„å¸§ï¼ˆå¦‚æœæœ‰ï¼‰
    if frames_to_trim > 0 and actual_frames > original_t:
        trim_amount = min(frames_to_trim, actual_frames - original_t)
        x_ungrouped = x_ungrouped[:, :-trim_amount]
    
    return x_ungrouped

# 3. è°ƒç”¨æ—¶ä¼ å…¥åŸå§‹å½¢çŠ¶ä¿¡æ¯
seraena_target = ungroup_and_unpad(seraena_target, frames_target.shape)
if seraena_target is not None:
    if seraena_target.shape == decoded.shape:
        seraena_loss = F.mse_loss(decoded, seraena_target)
        total_loss = total_loss + config.seraena_loss_weight * seraena_loss
    else:
        logger.warning(f"Shape mismatch: decoded {decoded.shape} vs seraena_target {seraena_target.shape}")
else:
    logger.warning("Skipping Seraena loss due to dimension mismatch")

# 4. å¯ç”¨DEBUGæ—¥å¿—æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
logging.basicConfig(level=logging.DEBUG)
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½
- **å‡½æ•°å¯¹ç§°æ€§**ï¼šç¡®ä¿ `pad_and_group` å’Œ `ungroup_and_unpad` å®Œå…¨å¯¹ç§°è®¾è®¡
- **å½¢çŠ¶ä¿¡æ¯ä¼ é€’**ï¼šå°†åŸå§‹å¼ é‡å½¢çŠ¶ä¿¡æ¯ä¼ é€’ç»™åå‘å˜æ¢å‡½æ•°
- **ç»´åº¦ä¸€è‡´æ€§éªŒè¯**ï¼šåœ¨æ¯ä¸ªå˜æ¢æ­¥éª¤éªŒè¯ç»´åº¦è®¡ç®—çš„æ­£ç¡®æ€§
- **è¯¦ç»†è°ƒè¯•æ—¥å¿—**ï¼šè®°å½•æ¯ä¸ªç»´åº¦å˜æ¢æ­¥éª¤çš„è¯¦ç»†ä¿¡æ¯
- **è¾¹ç•Œæ¡ä»¶å¤„ç†**ï¼šæ­£ç¡®å¤„ç† `frames_to_trim` å’Œå¸§æ•°ä¸æ•´é™¤çš„æƒ…å†µ
- **å‚æ•°é…ç½®éªŒè¯**ï¼šå¯åŠ¨æ—¶éªŒè¯ `n_frames`, `n_seraena_frames` ç­‰å‚æ•°çš„å…¼å®¹æ€§

### ğŸ” **é—®é¢˜æ’æŸ¥æ­¥éª¤**
1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**ï¼š
   ```python
   # åœ¨è®­ç»ƒè„šæœ¬ä¸­è®¾ç½®DEBUGçº§åˆ«
   logging.basicConfig(level=logging.DEBUG)
   ```

2. **æ£€æŸ¥å…³é”®å‚æ•°**ï¼š
   ```python
   print(f"âœ“ n_frames: {config.n_frames}")
   print(f"âœ“ n_seraena_frames: {config.n_seraena_frames}")
   print(f"âœ“ frames_to_trim: {getattr(model, 'frames_to_trim', 0)}")
   print(f"âœ“ batch_size: {config.train_batch_size}")
   
   # éªŒè¯å‚æ•°å…¼å®¹æ€§
   padded_frames = config.n_frames + getattr(model, 'frames_to_trim', 0)
   print(f"âœ“ padded_frames: {padded_frames}")
   print(f"âœ“ divisible by n_seraena_frames: {padded_frames % config.n_seraena_frames == 0}")
   ```

3. **è·Ÿè¸ªç»´åº¦å˜æ¢**ï¼š
   ```python
   # æŸ¥çœ‹DEBUGæ—¥å¿—ä¸­çš„å…³é”®ä¿¡æ¯
   # pad_and_group input shape: [N, T, C, H, W]
   # pad_and_group output shape: [groups, grouped_c, H, W]  
   # ungroup_and_unpad input shape: [groups, grouped_c, H, W]
   # After ungrouping: [N', T', C, H, W]
   # After removing padding: [N, T, C, H, W]
   ```

4. **éªŒè¯å½¢çŠ¶åŒ¹é…**ï¼š
   ```python
   print(f"âœ“ frames_target.shape: {frames_target.shape}")
   print(f"âœ“ decoded.shape: {decoded.shape}")  
   print(f"âœ“ seraena_target.shape: {seraena_target.shape if seraena_target else 'None'}")
   ```

### ğŸ’¡ **æ ¹æœ¬è§£å†³æ–¹æ¡ˆ**

**âœ… å·²å®æ–½çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ**ï¼š

1. **å¯¹ç§°å‡½æ•°è®¾è®¡**ï¼š
   - `pad_and_group`: `[N,T,C,H,W] â†’ [groups,grouped_c,H,W]`
   - `ungroup_and_unpad`: `[groups,grouped_c,H,W] + original_shape â†’ [N,T,C,H,W]`
   - å…³é”®ï¼šä¼ é€’åŸå§‹å½¢çŠ¶ä¿¡æ¯ï¼Œç¡®ä¿å¯é€†å˜æ¢

2. **æ™ºèƒ½è¾¹ç•Œå¤„ç†**ï¼š
   ```python
   # è‡ªåŠ¨è°ƒæ•´å¸§æ•°ç¡®ä¿æ•´é™¤
   if t % config.n_seraena_frames != 0:
       t_trimmed = (t // config.n_seraena_frames) * config.n_seraena_frames
       x_padded = x_padded[:, :t_trimmed]
   ```

3. **ç»´åº¦ä¸€è‡´æ€§éªŒè¯**ï¼š
   ```python
   expected_n_groups = original_n * actual_frames // config.n_seraena_frames
   if n_groups != expected_n_groups:
       logger.warning("Group count mismatch")
       return None
   ```

4. **é…ç½®å‚æ•°ä¼˜åŒ–å»ºè®®**ï¼š
   ```python
   # æ¨èé…ç½®ï¼ˆç¡®ä¿å…¼å®¹æ€§ï¼‰
   args.n_frames = 12           # åŸºç¡€å¸§æ•°
   args.n_seraena_frames = 3    # åˆ†ç»„å¤§å°  
   args.frames_to_trim = 3      # ä¿®å‰ªå¸§æ•°
   # æ€»å¸§æ•°ï¼š12+3=15ï¼Œèƒ½è¢«3æ•´é™¤ âœ“
   ```

5. **è°ƒè¯•å’Œç›‘æ§**ï¼š
   - DEBUGçº§åˆ«æ—¥å¿—è®°å½•æ¯æ­¥ç»´åº¦å˜æ¢
   - å½¢çŠ¶åŒ¹é…éªŒè¯é˜²æ­¢é™é»˜é”™è¯¯
   - è¯¦ç»†é”™è¯¯ä¿¡æ¯ä¾¿äºå¿«é€Ÿå®šä½é—®é¢˜

**ğŸš« ä¸å†éœ€è¦çš„ä¸´æ—¶æ–¹æ¡ˆ**ï¼š
- ~~ç¦ç”¨Seraenaè®­ç»ƒ~~ï¼ˆé—®é¢˜å·²æ ¹æœ¬è§£å†³ï¼‰
- ~~è·³è¿‡ç»´åº¦ä¸åŒ¹é…çš„æ‰¹æ¬¡~~ï¼ˆç°åœ¨èƒ½æ­£ç¡®å¤„ç†ï¼‰

---

## é”™è¯¯12: TAEHVå¸§æ•°ç»´åº¦ä¸åŒ¹é… - decodedä¸frames_targetä¸ä¸€è‡´

### ğŸš¨ é”™è¯¯ç°è±¡

**é”™è¯¯ä¿¡æ¯**ï¼š
```bash
RuntimeError: The size of tensor a (17) must match the size of tensor b (16) at non-singleton dimension 1

UserWarning: Using a target size (torch.Size([1, 16, 3, 480, 480])) that is different to the 
input size (torch.Size([1, 17, 3, 480, 480])). This will likely lead to incorrect results 
due to broadcasting.
  recon_loss = F.mse_loss(decoded, frames_target)
```

**å…·ä½“åœºæ™¯**ï¼š
- é…ç½® `n_frames = 19`
- `decoded` è¾“å‡ºå½¢çŠ¶: `[batch, 17, 3, 480, 480]`
- `frames_target` å½¢çŠ¶: `[batch, 16, 3, 480, 480]`
- ç»´åº¦ä¸åŒ¹é…å¯¼è‡´ MSE loss è®¡ç®—å¤±è´¥

### ğŸ” æ ¹æœ¬åŸå› 

**TAEHVæ¨¡å‹çš„ç¼–ç -è§£ç æœºåˆ¶**ï¼š

1. **æ—¶é—´ä¸‹é‡‡æ ·/ä¸Šé‡‡æ ·æ¯”ä¾‹**ï¼š
   - `decoder_time_upscale = (True, True)` â†’ 2æ¬¡æ—¶é—´ä¸Šé‡‡æ ·
   - æ€»ä¸Šé‡‡æ ·å€ç‡ï¼š2 Ã— 2 = **4x**
   - å¯¹åº”çš„ç¼–ç å™¨æœ‰ **4x æ—¶é—´ä¸‹é‡‡æ ·**

2. **frames_to_trim æœºåˆ¶**ï¼š
   ```python
   self.frames_to_trim = 2**sum(decoder_time_upscale) - 1 = 2^2 - 1 = 3
   ```
   - è§£ç å™¨è¾“å‡ºåä¼šè£å‰ªæ‰**å‰3å¸§**

3. **å®Œæ•´çš„ç¼–ç -è§£ç æµç¨‹**ï¼ˆä»¥ n_frames=19 ä¸ºä¾‹ï¼‰ï¼š
   ```
   è¾“å…¥: 19 å¸§
     â†“ ç¼–ç å™¨ï¼ˆ4xä¸‹é‡‡æ ·ï¼‰
   æ½œåœ¨è¡¨ç¤º: ceil(19/4) = 5 å¸§
     â†“ è§£ç å™¨ï¼ˆ4xä¸Šé‡‡æ ·ï¼‰
   åŸå§‹è¾“å‡º: 5 Ã— 4 = 20 å¸§
     â†“ è£å‰ªå‰3å¸§
   decoded: 20 - 3 = 17 å¸§ âœ“
   ```

4. **frames_target è®¡ç®—**ï¼š
   ```python
   frames_target = frames[:, :-model.frames_to_trim]
                 = frames[:, :-3]
                 = 19 - 3 = 16 å¸§ âŒ
   ```

5. **ç»´åº¦ä¸åŒ¹é…**ï¼š
   - `decoded`: 17 å¸§
   - `frames_target`: 16 å¸§
   - **17 â‰  16** â†’ RuntimeError

### ğŸ“Š æ­£ç¡®çš„å¸§æ•°è®¡ç®—å…¬å¼

è¦ç¡®ä¿ `decoded` å’Œ `frames_target` ç»´åº¦åŒ¹é…ï¼Œéœ€è¦æ»¡è¶³ï¼š

```python
decoded_frames = ceil(n_frames / 4) * 4 - 3
frames_target = n_frames - 3

# è¦æ±‚ï¼šdecoded_frames = frames_target
ceil(n_frames / 4) * 4 - 3 = n_frames - 3
ceil(n_frames / 4) * 4 = n_frames
```

**å…³é”®è§„åˆ™**ï¼š`n_frames` å¿…é¡»æ˜¯ **4 çš„å€æ•°**æˆ–ä½¿è§£ç åè£å‰ªçš„å¸§æ•°åŒ¹é…ï¼

### âœ… è§£å†³æ–¹æ³•

#### æ–¹æ¡ˆ1ï¼šä¿®æ­£ n_frames ä¸ºæ­£ç¡®å€¼ï¼ˆæ¨èï¼‰

**ä¿®æ”¹æ–‡ä»¶**: `training/configs/taehv_config_1gpu_h100.py`

```python
# âŒ é”™è¯¯é…ç½®
args.n_frames = 19  # decoded=17, target=16, ä¸åŒ¹é…ï¼

# âœ… æ­£ç¡®é…ç½®
args.n_frames = 20  # decoded=17, target=17, åŒ¹é…ï¼
```

**éªŒè¯ n_frames = 20**ï¼š
```
è¾“å…¥: 20 å¸§
ç¼–ç : ceil(20/4) = 5 å¸§
è§£ç : 5 Ã— 4 = 20 å¸§
è£å‰ª: 20 - 3 = 17 å¸§ (decoded) âœ“
ç›®æ ‡: 20 - 3 = 17 å¸§ (frames_target) âœ“
ç»“æœ: 17 = 17 âœ“ å®Œç¾åŒ¹é…ï¼
```

#### æ–¹æ¡ˆ2ï¼šå…¶ä»–åˆæ³•çš„å¸§æ•°é…ç½®

æ ¹æ®å…¬å¼ `ceil(n_frames/4)*4 - 3 = n_frames - 3`ï¼Œä»¥ä¸‹æ˜¯åˆæ³•é…ç½®ï¼š

| n_frames | ç¼–ç å | è§£ç å | è£å‰ªå(decoded) | frames_target | åŒ¹é…? | æ˜¾å­˜ä¼°ç®— |
|----------|--------|--------|----------------|---------------|-------|----------|
| 4 | 1 | 4 | 1 | 1 | âœ… | ~5GB |
| 8 | 2 | 8 | 5 | 5 | âœ… | ~10GB |
| 12 | 3 | 12 | 9 | 9 | âœ… | ~18GB |
| 16 | 4 | 16 | 13 | 13 | âœ… | ~25GB |
| **20** | **5** | **20** | **17** | **17** | **âœ…** | **~32GB** â­ |
| 24 | 6 | 24 | 21 | 21 | âœ… | ~40GB |
| 28 | 7 | 28 | 25 | 25 | âœ… | ~48GB |

**éæ³•é…ç½®ç¤ºä¾‹**ï¼ˆä¼šå¯¼è‡´é”™è¯¯ï¼‰ï¼š
| n_frames | decoded | frames_target | åŒ¹é…? | åŸå›  |
|----------|---------|---------------|-------|------|
| 13 | 13 | 10 | âŒ | 13 â‰  10 |
| 17 | 17 | 14 | âŒ | 17 â‰  14 |
| **19** | **17** | **16** | âŒ | 17 â‰  16ï¼ˆå½“å‰é”™è¯¯ï¼‰|
| 21 | 21 | 18 | âŒ | 21 â‰  18 |

### ğŸ”§ å®Œæ•´ä¿®å¤æ­¥éª¤

1. **ä¿®æ”¹å•å¡H100é…ç½®**ï¼š
```bash
# æ–‡ä»¶: training/configs/taehv_config_1gpu_h100.py
args.n_frames = 20  # ä¿®æ”¹ä¸º20
args.n_seraena_frames = 8  # ä¿æŒä¸å˜ï¼ˆ17/2â‰ˆ8ï¼‰
```

2. **å¯é€‰ï¼šè°ƒæ•´batch sizeä»¥é€‚åº”æ›´å¤šå¸§**ï¼š
```python
# å¦‚æœ20å¸§å ç”¨æ˜¾å­˜è¶…è¿‡é¢„æœŸ
args.train_batch_size = 1  # å·²ç»æ˜¯1ï¼Œä¿æŒä¸å˜
args.gradient_accumulation_steps = 16  # ä¿æŒæœ‰æ•ˆbatch=16
```

3. **éªŒè¯é…ç½®**ï¼š
```bash
# è¿è¡Œè®­ç»ƒ
./train_taehv_h100.sh 1 h100

# æœŸæœ›è¾“å‡ºï¼š
# decoded shape: [1, 17, 3, 480, 720]
# frames_target shape: [1, 17, 3, 480, 720]
# âœ“ ä¸å†æœ‰ç»´åº¦ä¸åŒ¹é…è­¦å‘Š
```

### ğŸ“ é€šç”¨å¸§æ•°é€‰æ‹©æŒ‡å—

**é€‰æ‹©åŸåˆ™**ï¼š
1. **å¿…é¡»æ»¡è¶³**ï¼š`n_frames = 4k` æˆ–ä½¿ `ceil(n_frames/4)*4 - 3 = n_frames - 3`
2. **æ˜¾å­˜è€ƒè™‘**ï¼šå¸§æ•°è¶Šå¤šï¼Œæ˜¾å­˜å ç”¨è¶Šé«˜
3. **è´¨é‡è€ƒè™‘**ï¼šæ›´å¤šå¸§ â†’ æ›´å¥½çš„æ—¶é—´è¿è´¯æ€§
4. **é€Ÿåº¦è€ƒè™‘**ï¼šæ›´å¤šå¸§ â†’ è®­ç»ƒé€Ÿåº¦æ›´æ…¢

**æ¨èé…ç½®**ï¼š

- **æµ‹è¯•/è°ƒè¯•**ï¼š`n_frames = 12` (~18GBï¼Œå¿«é€Ÿè¿­ä»£)
- **å•å¡H100**ï¼š`n_frames = 20` (~32GBï¼Œå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦) â­
- **å¤šå¡H100**ï¼š`n_frames = 16` (~25GB/å¡ï¼Œæ¨è)
- **æ˜¾å­˜å……è¶³**ï¼š`n_frames = 24` (~40GBï¼Œæœ€é«˜è´¨é‡)

### ğŸ›¡ï¸ é¢„é˜²æªæ–½

1. **é…ç½®éªŒè¯è„šæœ¬**ï¼š
```python
def validate_n_frames(n_frames):
    """éªŒè¯n_framesé…ç½®æ˜¯å¦åˆæ³•"""
    frames_to_trim = 3
    decoded_frames = ((n_frames + 3) // 4) * 4 - frames_to_trim
    target_frames = n_frames - frames_to_trim
    
    if decoded_frames != target_frames:
        print(f"âŒ n_frames={n_frames} ä¸åˆæ³•!")
        print(f"   decoded={decoded_frames}, target={target_frames}")
        return False
    
    print(f"âœ… n_frames={n_frames} åˆæ³•!")
    print(f"   decoded={decoded_frames}, target={target_frames}")
    return True

# æµ‹è¯•
validate_n_frames(19)  # âŒ ä¸åˆæ³•
validate_n_frames(20)  # âœ… åˆæ³•
```

2. **åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ æ³¨é‡Š**ï¼š
```python
# CRITICAL: n_frames å¿…é¡»æ»¡è¶³ ceil(n_frames/4)*4 - 3 = n_frames - 3
# åˆæ³•å€¼: 4, 8, 12, 16, 20, 24, 28, ...
args.n_frames = 20  # âœ“ éªŒè¯é€šè¿‡
```

3. **è®­ç»ƒè„šæœ¬å¯åŠ¨å‰æ£€æŸ¥**ï¼š
```python
# åœ¨ taehv_train.py ä¸­æ·»åŠ 
def validate_config(args, model):
    n_frames = args.n_frames
    frames_to_trim = model.frames_to_trim
    decoded_frames = ((n_frames + 3) // 4) * 4 - frames_to_trim
    target_frames = n_frames - frames_to_trim
    
    assert decoded_frames == target_frames, \
        f"Invalid n_frames={n_frames}: decoded={decoded_frames} != target={target_frames}"
    
    logger.info(f"âœ“ n_frames validation passed: {n_frames} â†’ {target_frames} frames")
```

### ğŸ“ ç›¸å…³é”™è¯¯

æ­¤é”™è¯¯ä¸ä»¥ä¸‹é—®é¢˜ç›¸å…³ï¼š
- [é”™è¯¯11: Seraenaå¼ é‡å½¢çŠ¶ä¸åŒ¹é…](#é”™è¯¯11-seraenaå¼ é‡å½¢çŠ¶ä¸åŒ¹é…é—®é¢˜) - ä¹Ÿæ¶‰åŠå¸§æ•°ç»´åº¦
- å¸§æ•°é…ç½®é”™è¯¯æ˜¯è®­ç»ƒå¤±è´¥çš„å¸¸è§åŸå› 

### ğŸ¯ ç»éªŒæ•™è®­

1. **ç†è§£æ¨¡å‹æ¶æ„è‡³å…³é‡è¦**ï¼š
   - å¿…é¡»äº†è§£ç¼–ç å™¨/è§£ç å™¨çš„æ—¶é—´ä¸‹é‡‡æ ·/ä¸Šé‡‡æ ·æ¯”ä¾‹
   - frames_to_trim çš„ä½œç”¨å’Œå½±å“
   - ç¼–ç -è§£ç çš„å®Œæ•´æµç¨‹

2. **ä¸æ˜¯æ‰€æœ‰çš„4çš„å€æ•°éƒ½åˆæ³•**ï¼š
   - `n_frames = 16` âœ… åˆæ³•ï¼ˆdecoded=13, target=13ï¼‰
   - `n_frames = 18` âŒ ä¸åˆæ³•ï¼ˆdecoded=17, target=15ï¼‰
   - å¿…é¡»é€šè¿‡å…¬å¼éªŒè¯

3. **é…ç½®éªŒè¯æ¯”è°ƒè¯•æ›´é«˜æ•ˆ**ï¼š
   - æå‰éªŒè¯é…ç½®å¯é¿å…æµªè´¹è®­ç»ƒæ—¶é—´
   - è‡ªåŠ¨åŒ–éªŒè¯è„šæœ¬æ˜¯æœ€ä½³å®è·µ

4. **æ–‡æ¡£å’Œæ³¨é‡Šçš„é‡è¦æ€§**ï¼š
   - åœ¨é…ç½®æ–‡ä»¶ä¸­æ˜ç¡®æ ‡æ³¨çº¦æŸæ¡ä»¶
   - æä¾›åˆæ³•å€¼åˆ—è¡¨å’ŒéªŒè¯å…¬å¼

---

## é”™è¯¯13: Seraenaå¸§æ•°ä¸èƒ½æ•´é™¤è­¦å‘Š - æ•°æ®æŸå¤±é—®é¢˜

### ğŸš¨ é”™è¯¯ç°è±¡

**è­¦å‘Šä¿¡æ¯**ï¼š
```bash
WARNING - __main__ - Frame count 20 is not divisible by n_seraena_frames 8
WARNING - __main__ - Shape mismatch: decoded torch.Size([1, 17, 3, 480, 480]) vs seraena_target torch.Size([1, 16, 3, 480, 480])
```

**å…·ä½“åœºæ™¯**ï¼š
- é…ç½® `n_frames = 20`, `n_seraena_frames = 8`
- `frames_target = 20 - 3 = 17` å¸§
- 17 ä¸èƒ½è¢« 8 æ•´é™¤ï¼š17 Ã· 8 = 2 ä½™ 1
- Seraena è‡ªåŠ¨è£å‰ªå¸§æ•°å¯¼è‡´ç»´åº¦ä¸åŒ¹é…

### ğŸ” æ ¹æœ¬åŸå› 

**Seraena çš„å¸§æ•°åˆ†ç»„æœºåˆ¶**ï¼š

1. **åˆ†ç»„è¦æ±‚**ï¼šSeraena éœ€è¦å°†è§†é¢‘å¸§åˆ†ç»„å¤„ç†ï¼Œè¦æ±‚æ€»å¸§æ•°èƒ½è¢« `n_seraena_frames` æ•´é™¤
2. **è‡ªåŠ¨è£å‰ªé€»è¾‘**ï¼š
   ```python
   # åœ¨ training/taehv_train.py ä¸­
   if t % config.n_seraena_frames != 0:
       logger.warning(f"Frame count {t} is not divisible by n_seraena_frames {config.n_seraena_frames}")
       # è£å‰ªåˆ°æœ€æ¥è¿‘çš„å¯æ•´é™¤æ•°
       t_trimmed = (t // config.n_seraena_frames) * config.n_seraena_frames
       x_padded = x_padded[:, :t_trimmed]  # æ•°æ®æŸå¤±ï¼
   ```

3. **æ•°æ®æŸå¤±åæœ**ï¼š
   - åŸå§‹å¸§æ•°ï¼š17 å¸§
   - è£å‰ªåï¼š17 // 8 * 8 = 16 å¸§
   - **ä¸¢å¤±1å¸§æ•°æ®**ï¼Œå½±å“è®­ç»ƒè´¨é‡

4. **ç»´åº¦ä¸åŒ¹é…**ï¼š
   - `decoded`: 17 å¸§ï¼ˆæ¥è‡ªTAEHVè§£ç å™¨ï¼‰
   - `seraena_target`: 16 å¸§ï¼ˆè¢«è£å‰ªåï¼‰
   - å¯¼è‡´æŸå¤±å‡½æ•°è®¡ç®—å¤±è´¥

### ğŸ“Š å¸§æ•°æ•´é™¤æ€§åˆ†æ

**å½“å‰é…ç½®é—®é¢˜**ï¼š
```
n_frames = 20 â†’ frames_target = 17
n_seraena_frames = 8
17 Ã· 8 = 2 ä½™ 1 âŒ ä¸èƒ½æ•´é™¤
```

**17 æ˜¯è´¨æ•°**ï¼Œåªæœ‰å› æ•° `[1, 17]`ï¼Œé€‰æ‹©æœ‰é™ã€‚

**å…¶ä»–åˆæ³•é…ç½®çš„å› æ•°åˆ†æ**ï¼š

| n_frames | frames_target | å¯ç”¨çš„ n_seraena_frames | æ¨èå€¼ | æ˜¾å­˜ä¼°ç®— |
|----------|---------------|------------------------|--------|----------|
| 16 | 13 | [1, 13] | 1 | ~25GB |
| **20 (å½“å‰)** | **17** | **[1, 17]** | **1 â­** | **~32GB** |
| 24 | 21 | [1, 3, 7, 21] | 3 æˆ– 7 | ~40GB |
| 28 | 25 | [1, 5, 25] | 5 | ~48GB |

### âœ… è§£å†³æ–¹æ³•

#### æ–¹æ¡ˆ1ï¼šä¿®æ”¹ n_seraena_framesï¼ˆæ¨èï¼‰

**ä¿®æ”¹æ–‡ä»¶**: `training/configs/taehv_config_1gpu_h100.py`

```python
# âŒ é”™è¯¯é…ç½®
args.n_seraena_frames = 8  # 17 Ã· 8 = 2 ä½™ 1ï¼Œæ•°æ®æŸå¤±

# âœ… æ­£ç¡®é…ç½®ï¼ˆæ¨èï¼‰
args.n_seraena_frames = 1  # 17 Ã· 1 = 17ï¼Œæ— æŸå¤±

# âœ… å¤‡é€‰é…ç½®
args.n_seraena_frames = 17  # 17 Ã· 17 = 1ï¼Œæ— æŸå¤±ä½†è®¡ç®—æ•ˆç‡è¾ƒä½
```

**ä¸ºä»€ä¹ˆæ¨è n_seraena_frames = 1**ï¼š
- âœ… å®Œå…¨é¿å…æ•°æ®æŸå¤±
- âœ… è®¡ç®—æ•ˆç‡æœ€é«˜
- âœ… å…¼å®¹æ€§æœ€å¥½
- âœ… è®­ç»ƒæ›´ç¨³å®š

#### æ–¹æ¡ˆ2ï¼šæ›´æ¢ä¸ºæœ‰æ›´å¤šå› æ•°çš„å¸§æ•°é…ç½®

```python
# ä½¿ç”¨ n_frames = 24 (æ›´çµæ´»)
args.n_frames = 24  # frames_target = 21
args.n_seraena_frames = 3  # 21 Ã· 3 = 7 âœ“

# éªŒè¯
# è¾“å…¥: 24 å¸§ â†’ ç¼–ç : ceil(24/4) = 6 â†’ è§£ç : 24 â†’ è£å‰ª: 21
# frames_target = 21, decoded = 21 âœ… åŒ¹é…
# 21 Ã· 3 = 7 âœ… æ•´é™¤
```

### ğŸ”§ å®Œæ•´ä¿®å¤æ­¥éª¤

1. **ä¿®å¤é…ç½®**ï¼š
```bash
# ä¿®æ”¹ training/configs/taehv_config_1gpu_h100.py
args.n_seraena_frames = 1  # ä» 8 æ”¹ä¸º 1
```

2. **é‡æ–°å¯åŠ¨è®­ç»ƒ**ï¼š
```bash
# åœæ­¢å½“å‰è®­ç»ƒ (Ctrl+C)
./train_taehv_h100.sh 1 h100
```

3. **éªŒè¯ä¿®å¤**ï¼š
```bash
# æœŸæœ›è¾“å‡ºï¼š
# âœ… ä¸å†æœ‰ "Frame count ... is not divisible" è­¦å‘Š
# âœ… ä¸å†æœ‰ "Shape mismatch" è­¦å‘Š
# âœ… decoded å’Œ seraena_target éƒ½æ˜¯ 17 å¸§
```

### ğŸ“ é…ç½®éªŒè¯è„šæœ¬

```python
def validate_seraena_config(n_frames, n_seraena_frames):
    """éªŒè¯ Seraena é…ç½®çš„å…¼å®¹æ€§"""
    frames_target = n_frames - 3
    
    print(f"é…ç½®éªŒè¯: n_frames={n_frames}, n_seraena_frames={n_seraena_frames}")
    print(f"frames_target = {frames_target}")
    
    if frames_target % n_seraena_frames == 0:
        groups = frames_target // n_seraena_frames
        print(f"âœ… æ•´é™¤æ£€æŸ¥é€šè¿‡: {frames_target} Ã· {n_seraena_frames} = {groups}")
        print(f"âœ… æ— æ•°æ®æŸå¤±")
        return True
    else:
        remainder = frames_target % n_seraena_frames
        trimmed = (frames_target // n_seraena_frames) * n_seraena_frames
        loss = frames_target - trimmed
        print(f"âŒ æ•´é™¤æ£€æŸ¥å¤±è´¥: {frames_target} Ã· {n_seraena_frames} = {frames_target//n_seraena_frames} ä½™ {remainder}")
        print(f"âŒ æ•°æ®æŸå¤±: {loss} å¸§ ({frames_target} â†’ {trimmed})")
        return False

# æµ‹è¯•
validate_seraena_config(20, 8)   # âŒ å½“å‰é…ç½®
validate_seraena_config(20, 1)   # âœ… æ¨èé…ç½®
validate_seraena_config(24, 3)   # âœ… æ›¿ä»£é…ç½®
```

### ğŸ›¡ï¸ é¢„é˜²æªæ–½

1. **é…ç½®æ–‡ä»¶æ³¨é‡Š**ï¼š
```python
# CRITICAL: frames_target å¿…é¡»èƒ½è¢« n_seraena_frames æ•´é™¤
# frames_target = n_frames - 3
# éªŒè¯: (n_frames - 3) % n_seraena_frames == 0
args.n_seraena_frames = 1  # âœ“ å…¼å®¹æ‰€æœ‰å¸§æ•°
```

2. **å¯åŠ¨æ—¶éªŒè¯**ï¼š
```python
# åœ¨ taehv_train.py ä¸­æ·»åŠ 
def validate_seraena_config(config):
    frames_target = config.n_frames - 3
    if frames_target % config.n_seraena_frames != 0:
        raise ValueError(
            f"Invalid configuration: frames_target ({frames_target}) is not divisible by "
            f"n_seraena_frames ({config.n_seraena_frames}). "
            f"This will cause data loss and training instability."
        )
    logger.info(f"âœ“ Seraena config validated: {frames_target} Ã· {config.n_seraena_frames} = {frames_target // config.n_seraena_frames}")
```

### ğŸ“ ç›¸å…³é”™è¯¯

æ­¤é”™è¯¯ä¸ä»¥ä¸‹é—®é¢˜ç›¸å…³ï¼š
- [é”™è¯¯12: TAEHVå¸§æ•°ç»´åº¦ä¸åŒ¹é…](#é”™è¯¯12-taehvå¸§æ•°ç»´åº¦ä¸åŒ¹é…-decodedä¸frames_targetä¸ä¸€è‡´) - å¸§æ•°é…ç½®çš„ä¸Šæ¸¸é—®é¢˜
- [é”™è¯¯11: Seraenaå¼ é‡å½¢çŠ¶ä¸åŒ¹é…](#é”™è¯¯11-seraenaå¼ é‡å½¢çŠ¶ä¸åŒ¹é…é—®é¢˜) - ç›¸åŒçš„ç»´åº¦ä¸åŒ¹é…æ ¹å› 

### ğŸ¯ ç»éªŒæ•™è®­

1. **ç†è§£æ‰€æœ‰ç»„ä»¶çš„çº¦æŸ**ï¼š
   - TAEHV éœ€è¦ç‰¹å®šçš„å¸§æ•°è§„åˆ™
   - Seraena éœ€è¦å¸§æ•°èƒ½è¢«åˆ†ç»„æ•°æ•´é™¤
   - ä¸¤è€…çš„çº¦æŸéœ€è¦åŒæ—¶æ»¡è¶³

2. **é¿å…æ•°æ®æŸå¤±**ï¼š
   - è‡ªåŠ¨è£å‰ªçœ‹ä¼¼"è§£å†³"äº†è­¦å‘Šï¼Œä½†å®é™…é€ æˆè®­ç»ƒæ•°æ®ä¸¢å¤±
   - æ­£ç¡®çš„åšæ³•æ˜¯è°ƒæ•´é…ç½®è€Œä¸æ˜¯æ¥å—æ•°æ®æŸå¤±

3. **è´¨æ•°å¸§æ•°çš„æŒ‘æˆ˜**ï¼š
   - 17ã€13ã€19 ç­‰è´¨æ•°åªæœ‰å¾ˆå°‘çš„å› æ•°é€‰æ‹©
   - é€‰æ‹©æœ‰æ›´å¤šå› æ•°çš„å¸§æ•°é…ç½®å¯æä¾›æ›´å¤§çµæ´»æ€§

4. **é…ç½®éªŒè¯çš„é‡è¦æ€§**ï¼š
   - å¤æ‚çš„å¤šç»„ä»¶ç³»ç»Ÿéœ€è¦å…¨é¢çš„é…ç½®éªŒè¯
   - å¯åŠ¨æ—¶æ£€æŸ¥å¯é¿å…è¿è¡Œæ—¶çš„é—®é¢˜

---

## é”™è¯¯14: CogVideoXæ¨¡å¼ç»´åº¦ä¸åŒ¹é… - decoded vs frames_target

**é”™è¯¯ä¿¡æ¯**:
```
RuntimeError: The size of tensor a (16) must match the size of tensor b (13) at non-singleton dimension 1
UserWarning: Using a target size (torch.Size([2, 13, 3, 480, 480])) that is different to the input size (torch.Size([2, 16, 3, 480, 480]))
```

### é”™è¯¯åˆ†æ

å½“ä½¿ç”¨CogVideoXé¢„è®­ç»ƒæ¨¡å‹(`taecvx.pth`)æ—¶ï¼ŒTAEHVè¿›å…¥ç‰¹æ®Šçš„CogVideoXå…¼å®¹æ¨¡å¼ï¼š

**é—®é¢˜æ ¹æº**:
1. **æ¨¡å‹æ£€æµ‹**: `pretrained_model_path`åŒ…å«`"taecvx"` â†’ `is_cogvideox = True`
2. **è§£ç è¡Œä¸º**: ç¼–ç å¸§æ•°ä¸ºå¶æ•°æ—¶ â†’ `skip_trim = True` â†’ è§£ç è¾“å‡ºä¸è£å‰ª
3. **Targetè®¡ç®—**: è®­ç»ƒä»£ç ä»ç„¶è£å‰ªäº†`frames_target`
4. **ç»´åº¦ä¸åŒ¹é…**: `decoded=16å¸§` vs `frames_target=13å¸§`

**è®¡ç®—é“¾æ¡**:
```
è¾“å…¥: 16å¸§ â†’ ç¼–ç : ceil(16/4)=4å¸§ â†’ è§£ç : 4Ã—4=16å¸§ (è·³è¿‡è£å‰ª)
Target: 16å¸§ â†’ è£å‰ª: 16-3=13å¸§
ç»“æœ: decoded[16] â‰  target[13] â†’ ç»´åº¦ä¸åŒ¹é…
```

### è§£å†³æ–¹æ¡ˆ

**æ–¹æ³•1: ä¿®å¤è®­ç»ƒé€»è¾‘** (å·²å®æ–½)
```python
# training/taehv_train.py ä¿®å¤é€»è¾‘
will_skip_trim = model.is_cogvideox and encoded.shape[1] % 2 == 0
if will_skip_trim:
    frames_target = frames  # CogVideoXæ¨¡å¼ä¸è£å‰ª
else:
    frames_target = frames[:, :-model.frames_to_trim]  # æ­£å¸¸æ¨¡å¼è£å‰ª
```

### é¢„é˜²æªæ–½

1. **é…ç½®éªŒè¯è„šæœ¬**:
```bash
# æ£€æŸ¥æ¨¡å‹æ¨¡å¼å’Œå¸§æ•°åŒ¹é…æ€§
python -c "
from models.taehv import TAEHV
model = TAEHV(checkpoint_path='checkpoints/taecvx.pth')
n_frames = 16
encoded_frames = (n_frames + 3) // 4
print(f'CogVideoXæ¨¡å¼: {model.is_cogvideox}')
print(f'è¾“å…¥å¸§æ•°: {n_frames}, ç¼–ç å¸§æ•°: {encoded_frames}')
if model.is_cogvideox and encoded_frames % 2 == 0:
    print(f'å°†è·³è¿‡è£å‰ªï¼Œtargetå¸§æ•°: {n_frames}')
else:
    print(f'æ­£å¸¸è£å‰ªï¼Œtargetå¸§æ•°: {n_frames - 3}')
"
```

2. **ç›¸å…³é”™è¯¯**:
   - é”™è¯¯12: æ ‡å‡†TAEHVæ¨¡å¼çš„å¸§æ•°ä¸åŒ¹é…
   - é”™è¯¯13: Seraenaå¸§æ•°æ•´é™¤é—®é¢˜

---

## é”™è¯¯15: CogVideoXè§£ç è¾“å‡ºå¸§æ•°å¼‚å¸¸ - 19å¸§vsé…ç½®16å¸§

**é”™è¯¯ä¿¡æ¯**:
```
WARNING - Frame count 19 is not divisible by n_seraena_frames 4
```

### é”™è¯¯åˆ†æ

ä½¿ç”¨CogVideoXé¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œè§£ç å™¨çš„å®é™…è¾“å‡ºå¸§æ•°ä¸ç†è®ºè®¡ç®—ä¸ç¬¦ï¼š

**é—®é¢˜é“¾æ¡**:
1. **é…ç½®å¸§æ•°**: `n_frames = 16`
2. **ç¼–ç å¸§æ•°**: `ceil(16/4) = 4`
3. **ç†è®ºè§£ç **: `4 Ã— 4 = 16å¸§`
4. **å®é™…è§£ç **: `19å¸§` âŒ (CogVideoXå†…éƒ¨é€»è¾‘)
5. **Seraenaæ£€æŸ¥**: `19 Ã· 4 = 4ä½™3` â†’ ä¸èƒ½æ•´é™¤ â†’ è­¦å‘Š

**æ ¹å› **:
CogVideoXè§£ç å™¨æœ‰å¤æ‚çš„æ—¶é—´ä¸Šé‡‡æ ·é€»è¾‘ï¼Œä¸æ˜¯ç®€å•çš„çº¿æ€§æ˜ å°„ï¼Œå®é™…è¾“å‡ºå¸§æ•°å¯èƒ½ä¸ `ç¼–ç å¸§æ•° Ã— 4` ä¸åŒã€‚

### è§£å†³æ–¹æ¡ˆ

**æ–¹æ¡ˆ1: è°ƒæ•´n_seraena_frames** (æ¨è)
```python
# training/configs/taehv_config_h100.py
args.n_seraena_frames = 1  # é€‚é…ä»»æ„å¸§æ•°ï¼Œæ— æ•°æ®æŸå¤±
```

**æ–¹æ¡ˆ2: é¢„è£å‰ªframes_target**
```python
# åœ¨Seraenaå¤„ç†å‰è£å‰ªä¸ºå¯æ•´é™¤çš„å¸§æ•°
target_frames = 16  # 4çš„å€æ•°
frames_target = frames_target[:, :target_frames]  # ä¼šä¸¢å¤±3å¸§
```

### é¢„é˜²æªæ–½

1. **å¸§æ•°éªŒè¯è„šæœ¬**:
```bash
# æ£€æŸ¥å®é™…è§£ç è¾“å‡ºå¸§æ•°
python -c "
from models.taehv import TAEHV
import torch
model = TAEHV(checkpoint_path='checkpoints/taecvx.pth')
dummy_input = torch.randn(1, 16, 3, 256, 256)
encoded = model.encode_video(dummy_input)
decoded = model.decode_video(encoded)
print(f'è¾“å…¥: {dummy_input.shape[1]}å¸§')
print(f'ç¼–ç : {encoded.shape[1]}å¸§') 
print(f'è§£ç : {decoded.shape[1]}å¸§')
"
```

2. **é…ç½®å»ºè®®**:
   - ä½¿ç”¨ `n_seraena_frames = 1` æœ€å®‰å…¨ï¼ˆé€‚é…ä»»æ„å¸§æ•°ï¼‰
   - æˆ–é€‰æ‹©19çš„å› æ•°ï¼š`1, 19`

### ç›¸å…³é”™è¯¯
- é”™è¯¯13: å…¶ä»–å¸§æ•°ä¸èƒ½æ•´é™¤çš„æƒ…å†µ
- é”™è¯¯14: CogVideoXæ¨¡å¼ç»´åº¦ä¸åŒ¹é…

---

## é”™è¯¯16: Seraenaå‚æ•°ç»´åº¦ä¸åŒ¹é… - å®é™…å¸§æ•°vsé…ç½®å¸§æ•°

**é”™è¯¯ä¿¡æ¯**:
```
WARNING - Seraena training failed: The size of tensor a (38) must match the size of tensor b (32) at non-singleton dimension 0, skipping adversarial loss
```

### é”™è¯¯åˆ†æ

å½“CogVideoXè§£ç è¾“å‡ºå®é™…å¸§æ•°ä¸é…ç½®å¸§æ•°ä¸åŒæ—¶ï¼ŒSeraenaçš„ä¸‰ä¸ªè¾“å…¥å‚æ•°ç»´åº¦ä¸åŒ¹é…ï¼š

**é—®é¢˜é“¾æ¡**:
1. **å®é™…æ•°æ®**: CogVideoXè§£ç è¾“å‡º19å¸§
2. **å‚æ•°1&2**: `pad_and_group(frames_target)` å’Œ `pad_and_group(decoded)`
   - åŸºäºå®é™…19å¸§ â†’ è¾“å‡ºç»´åº¦ `batch_size Ã— 19 = 38`
3. **å‚æ•°3**: `encoded.mean().repeat_interleave(config.n_frames//n_seraena_frames)`
   - åŸºäºé…ç½®16å¸§ â†’ è¾“å‡ºç»´åº¦ `batch_size Ã— 16 = 32`
4. **ç»´åº¦ä¸åŒ¹é…**: `38 â‰  32` â†’ Seraenaè°ƒç”¨å¤±è´¥

**æ ¹å› **:
ç¬¬ä¸‰ä¸ªå‚æ•°çš„è®¡ç®—ä½¿ç”¨äº†é…ç½®æ–‡ä»¶ä¸­çš„`config.n_frames`ï¼Œè€Œä¸æ˜¯å®é™…çš„`frames_target.shape[1]`ã€‚

### è§£å†³æ–¹æ¡ˆ

**ä¿®å¤ä»£ç ** (å·²å®æ–½)
```python
# training/taehv_train.py ç¬¬440-450è¡Œ
# ä½¿ç”¨å®é™…å¸§æ•°è€Œä¸æ˜¯é…ç½®å¸§æ•°
actual_frames = frames_target.shape[1]  # å®é™…å¸§æ•°ï¼ˆ19ï¼‰
repeat_times = actual_frames // config.n_seraena_frames  # 19Ã·1=19

seraena_target, seraena_debug = seraena.step_and_make_correction_targets(
    pad_and_group(frames_target),     # 38ç»´åº¦
    pad_and_group(decoded),          # 38ç»´åº¦  
    encoded.mean(1, keepdim=True).repeat_interleave(
        repeat_times, dim=1          # ä½¿ç”¨19è€Œé16
    ).flatten(0, 1)                  # 38ç»´åº¦ âœ“
)
```

### é¢„é˜²æªæ–½

1. **åŠ¨æ€å¸§æ•°æ£€æµ‹**:
```python
# æ€»æ˜¯ä½¿ç”¨å®é™…å¸§æ•°è¿›è¡Œè®¡ç®—
actual_frames = tensor.shape[1]
repeat_factor = actual_frames // config.n_seraena_frames
```

2. **ç»´åº¦éªŒè¯**:
```python
# åœ¨Seraenaè°ƒç”¨å‰éªŒè¯ç»´åº¦åŒ¹é…
assert param1.shape[0] == param2.shape[0] == param3.shape[0]
```

### ç›¸å…³é”™è¯¯
- é”™è¯¯15: CogVideoXè§£ç è¾“å‡ºå¸§æ•°å¼‚å¸¸
- é”™è¯¯14: CogVideoXæ¨¡å¼ç»´åº¦ä¸åŒ¹é…

---

é€šè¿‡ä»¥ä¸Šæªæ–½ï¼ŒTAEHVè®­ç»ƒå·²å®ç°é«˜åº¦ç¨³å®šæ€§ï¼Œèƒ½å¤Ÿä»å„ç§é”™è¯¯ä¸­è‡ªåŠ¨æ¢å¤å¹¶ç»§ç»­è®­ç»ƒã€‚
