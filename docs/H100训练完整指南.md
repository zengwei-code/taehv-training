# TAEHV H100 训练完整指南

## 📖 目录
- [项目概述](#项目概述)
- [快速开始](#快速开始)
- [配置说明](#配置说明)
- [使用示例](#使用示例)
- [A800测试](#A800测试)
- [服务器部署](#服务器部署)
- [性能优化](#性能优化)
- [故障排除](#故障排除)

---

## 🎯 项目概述

本项目提供了一套完整的TAEHV模型训练解决方案，特别针对H100 80G环境进行了优化，支持从测试环境到生产环境的无缝迁移。

### 📁 项目结构

```
my_taehv_training/
├── accelerate_configs/
│   ├── deepspeed_1gpu.yaml       # 单卡配置 (DeepSpeed优化) 
│   ├── deepspeed_8gpu.yaml       # 8卡配置 (H100/A800通用) ⭐
│   └── deepspeed_16gpu.yaml      # 16卡配置
├── training/configs/
│   ├── taehv_config.py           # 测试配置
│   ├── taehv_config_1gpu_h100.py # 单卡H100配置
│   ├── taehv_config_h100.py      # 8卡H100生产配置 ⭐
│   └── taehv_config_a800.py      # A800测试配置
├── train_taehv.sh                # 原启动脚本
├── train_taehv_h100.sh           # 统一生产脚本 (支持1/8/16卡) ⭐
└── docs/H100训练完整指南.md        # 本文档
```

### ✨ 主要特性

1. **灵活的GPU配置** - 支持单卡、8卡、16卡训练
2. **H100专用优化** - Native BF16、Flash Attention 2、TF32加速
3. **A800兼容性** - 支持A800环境测试H100脚本
4. **生产环境支持** - 几百万MP4数据集，高分辨率720×480
5. **易用性提升** - 统一脚本、彩色输出、智能错误检查
6. **完整功能** - Seraena对抗训练、参考VAE、xformers优化

---

## 🚀 快速开始

### 一键启动命令

```bash
# 单卡H100快速测试 (推荐用于开发调试)
./train_taehv_h100.sh 1 1gpu_h100

# H100 8卡生产训练 (推荐用于生产)
./train_taehv_h100.sh 8 h100

# A800 8卡测试H100脚本
./train_taehv_h100.sh 8 a800

# 16卡大规模训练
./train_taehv_h100.sh 16 h100

# 查看帮助
./train_taehv_h100.sh --help
```

### 支持的配置组合

| GPU数量 | 配置类型 | 使用场景 | 命令示例 |
|---------|----------|----------|----------|
| 1卡 | 1gpu_h100 | 快速测试/调试 | `./train_taehv_h100.sh 1 1gpu_h100` |
| 8卡 | h100 | H100生产训练 | `./train_taehv_h100.sh 8 h100` |
| 8卡 | a800 | A800测试H100脚本 | `./train_taehv_h100.sh 8 a800` |
| 16卡 | h100 | 大规模训练 | `./train_taehv_h100.sh 16 h100` |

---

## ⚙️ 配置说明

### 分辨率配置更新

**最新配置：720×480高分辨率训练**

| 参数 | 单卡H100 | 8卡H100 | 8卡A800 | 说明 |
|------|----------|---------|---------|------|
| height | 480 | 480 | 256 | 视频高度 |
| width | 720 | 720 | 384 | 视频宽度 |
| n_frames | 13 | 16 | 11 | 帧数（考虑frames_to_trim=3） |
| frames_target | 10 | 13 | 8 | 实际训练帧数 |
| batch_size | 2 | 2 | 1 | 每卡批次大小 |
| grad_accum | 8 | 4 | 4 | 梯度累积步数 |
| effective_batch | 16 | 64 | 32 | 有效批次大小 |

### 性能对比

| 指标 | 单卡H100 | 8卡H100 | 8卡A800 | 说明 |
|------|----------|---------|---------|------|
| 分辨率 | 720×480 | 720×480 | 384×256 | 高分辨率训练 |
| 有效批次大小 | 16 | 64 | 32 | 单卡vs多卡权衡 |
| 显存使用/卡 | ~30GB | ~35GB | ~15GB | 充分利用H100 80GB |
| 预期训练速度 | ~2-3 it/s | ~0.3-0.5 it/s | ~1.5-2 it/s | 单卡更快 |
| Seraena | ✅ | ✅ | ❌ | 对抗训练 |
| 参考VAE | ✅ | ✅ | ❌ | 额外监督 |
| 适用场景 | 快速迭代 | 生产训练 | 测试验证 | - |

---

## 📚 使用示例

### 单卡H100快速测试

单卡配置适合快速迭代、模型调试和小规模实验：

```bash
# 单卡H100基本训练（720×480高分辨率）
./train_taehv_h100.sh 1 1gpu_h100

# 调试模式（详细日志）
./train_taehv_h100.sh 1 1gpu_h100 --debug

# 从检查点恢复
./train_taehv_h100.sh 1 1gpu_h100 --resume output/1gpu_h100_test_xxx/checkpoint-1000
```

**单卡配置特点**：
- ✅ **快速启动**：无需多卡通信配置，启动速度快（~2-3 it/s）
- ✅ **高分辨率**：720×480，充分利用H100 80GB显存
- ✅ **完整功能**：支持Seraena、参考VAE、Flash Attention 2
- ✅ **显存使用**：~30GB/80GB，留有充足余量
- ✅ **适合场景**：代码调试、超参数调优、小规模数据集训练

### 开发测试阶段（多卡）

```bash
# 快速验证代码和配置
./train_taehv_h100.sh 8 test

# 调试模式
./train_taehv_h100.sh 8 test --debug

# 短时间测试运行
timeout 300 ./train_taehv_h100.sh 8 test
```

### 生产训练阶段

```bash
# 标准H100训练
./train_taehv_h100.sh 8 h100

# 从检查点恢复
./train_taehv_h100.sh 8 h100 --resume output/xxx/checkpoint-5000

# 后台运行
nohup ./train_taehv_h100.sh 8 h100 > training.log 2>&1 &

# 监控训练进度
tail -f training.log
```

### 大规模训练

```bash
# 16卡超大规模训练
./train_taehv_h100.sh 16 h100

# 多节点训练（两台8卡服务器）
MASTER_ADDR=node1 RANK=0 ./train_taehv_h100.sh 8 h100  # 节点1
MASTER_ADDR=node1 RANK=1 ./train_taehv_h100.sh 8 h100  # 节点2
```

---

## 🧪 A800测试

### A800与H100差异

| 特性 | A800 | H100 | 备注 |
|------|------|------|------|
| 显存 | 80GB | 80GB | 相同 |
| BF16性能 | 支持但较慢 | 原生优化 | H100更高效 |
| DeepSpeed配置 | 共享配置 | 共享配置 | 统一使用deepspeed_8gpu.yaml |
| Flash Attention | 完全支持 | 完全支持 | 已安装flash-attn 2.8.3 |</thinking>

### A800测试H100脚本

```bash
# 使用A800配置测试（共享DeepSpeed配置）
./train_taehv_h100.sh 8 a800

# A800保守参数设置
# - batch_size: 1 (更小)
# - gradient_accumulation_steps: 8 (更多)
# - n_frames: 12 (减少帧数)
# - 启用Flash Attention 2.8.3优化
# - 使用与H100相同的DeepSpeed配置
```

### A800优化建议

1. **显存优化**：更小的batch size，更多梯度累积
2. **配置简化**：与H100共享DeepSpeed配置，减少维护成本
3. **加速优化**：启用Flash Attention 2.8.3和xformers双重加速
4. **监控重点**：GPU利用率和通信延迟

### 🚀 Flash Attention 加速效果

**已安装库**：
- ✅ flash-attn 2.8.3 - 最新版本，完全兼容
- ✅ xformers 0.0.28 - 内存优化加速

**性能提升**：
| 模块 | 速度提升 | 显存节省 | 影响范围 |
|------|----------|----------|----------|
| CogVideoX VAE | +10-15% | -15-20% | 验证阶段 |
| 整体训练 | +2-5% | +5-10% | 全程优化 |

**自动启用**：无需手动配置，VAE会自动选择最佳attention实现

---

## 🖥️ 服务器部署

### 环境要求

#### 硬件要求
- [ ] 8x NVIDIA H100 80GB GPU (或A800)
- [ ] 足够的CPU内存 (建议 ≥ 512GB)
- [ ] 高速存储 (NVMe SSD, ≥ 10TB)
- [ ] 高带宽网络 (InfiniBand/100GbE)

#### 软件环境
- [ ] Ubuntu 20.04+ / CentOS 8+
- [ ] NVIDIA Driver ≥ 525.60.13
- [ ] CUDA ≥ 12.0
- [ ] Python 3.8+
- [ ] conda/miniconda

### 迁移步骤

#### 1. 环境配置
```bash
# 创建conda环境
conda create -n taehv_h100 python=3.10
conda activate taehv_h100

# 安装PyTorch (H100优化版本)
pip install torch==2.5.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# 安装训练依赖
pip install accelerate==1.10.1 deepspeed==0.17.6 diffusers==0.35.1
pip install transformers tensorboard opencv-python pillow easydict pytz tqdm
```

#### 2. 系统优化
```bash
# 设置GPU性能模式
sudo nvidia-smi -pm 1
sudo nvidia-smi -ac 1593,1980  # H100最大频率

# 设置系统参数
echo 'net.core.rmem_default = 262144' | sudo tee -a /etc/sysctl.conf
echo 'net.core.rmem_max = 16777216' | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
```

#### 3. 数据迁移
```bash
# 创建生产数据目录
mkdir -p /data/production/videos
mkdir -p /data/production/annotations

# 迁移视频数据
rsync -av --progress source_server:/path/to/videos/ /data/production/videos/

# 验证数据完整性
find /data/production/videos -name "*.mp4" | wc -l
```

### 部署验证

```bash
# 检查GPU状态
nvidia-smi

# 验证Python环境
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'GPU count: {torch.cuda.device_count()}')"

# 快速测试
./train_taehv_h100.sh 4 test

# 生产环境短时试运行
timeout 300 ./train_taehv_h100.sh 8 h100
```

---

## ⚡ 性能优化

### 监控指标

#### 关键性能指标
- GPU利用率 > 95%
- GPU内存使用率 70-85%
- GPU温度 < 83°C
- 通信带宽利用率 > 80%

#### 监控命令
```bash
# GPU实时监控
watch -n 2 nvidia-smi

# 详细GPU状态
nvidia-smi --query-gpu=index,name,temperature.gpu,utilization.gpu,utilization.memory,memory.used,memory.total --format=csv,noheader

# 训练指标监控
tensorboard --logdir output/latest/logs/
```

### 性能调优

#### 显存优化
```bash
# 如果显存不足，调整配置文件
# taehv_config_h100.py
train_batch_size = 1              # 减少batch size
gradient_accumulation_steps = 8   # 增加累积步数
n_frames = 12                     # 减少帧数
```

#### 通信优化
```bash
# 增加NCCL超时时间
export NCCL_TIMEOUT=14400  # 4小时

# 调整通信参数
export NCCL_BUFFSIZE=33554432  # 32MB buffer
```

#### 数据加载优化
```python
# 在配置文件中调整
dataloader_num_workers = 32       # 根据CPU核心数
prefetch_factor = 8              # 增加预取
persistent_workers = True        # 保持worker存活
```

---

## 🐛 故障排除

### 常见问题及解决方案

#### 1. CUDA内存不足
```
错误: CUDA out of memory
```
**解决方案**：
- **单卡训练**：减少batch_size或n_frames
- **多卡训练**：减少batch_size或使用更少GPU
- 增加gradient_accumulation_steps
- 减少n_frames或分辨率
- 考虑使用单卡配置（`1gpu_h100`）进行快速测试

#### 2. NCCL通信超时
```
错误: NCCL timeout
```
**解决方案**：
```bash
export NCCL_TIMEOUT=14400
export NCCL_P2P_DISABLE=1
```

#### 3. 数据加载慢
```
警告: DataLoader worker timeout
```
**解决方案**：
- 增加dataloader_num_workers
- 使用SSD存储训练数据
- 检查网络带宽

#### 4. 梯度爆炸/消失
```
错误: Loss is NaN
```
**解决方案**：
- 降低学习率
- 检查梯度裁剪设置
- 使用更稳定的优化器参数

### 调试工具

#### 启用详细日志
```bash
# 启用调试模式
./train_taehv_h100.sh 8 h100 --debug

# NCCL调试信息
NCCL_DEBUG=INFO ./train_taehv_h100.sh 8 h100

# PyTorch分布式调试
export TORCH_DISTRIBUTED_DEBUG=INFO
```

#### 性能分析
```bash
# 启用性能分析
./train_taehv_h100.sh 8 h100 --profile

# GPU性能分析
nsys profile --gpu-metrics-device=all python training/taehv_train.py
```

---

## 📊 性能基准

### 预期性能指标

| 配置 | GPU数量 | 分辨率 | Batch Size | 显存使用 | 训练速度 | 完成时间 |
|------|---------|--------|------------|----------|----------|----------|
| H100 | 8卡 | 720×480 | 64 (8×2×4) | ~65GB/卡 | ~2.5 it/s | 24-48小时 |
| A800 | 8卡 | 720×480 | 64 (8×1×8) | ~60GB/卡 | ~2.0 it/s | 36-60小时 |
| 测试 | 4卡 | 128×128 | 32 (4×2×4) | ~20GB/卡 | ~1.5 it/s | 验证用途 |

### 优化建议

1. **H100环境**：
   - 充分利用80GB显存
   - 启用所有H100专用优化
   - 使用大Batch Size和高分辨率

2. **A800环境**：
   - 使用保守的batch size设置
   - 关闭可能不兼容的高级特性
   - 重点监控通信延迟

3. **通用优化**：
   - 保持GPU利用率>95%
   - 定期清理检查点文件
   - 使用高速存储系统

---

## 🎉 总结

这套H100训练解决方案完全解决了多卡配置切换问题：

✅ **一键切换** - 支持4/8/16卡，H100/A800环境  
✅ **高分辨率** - 720×480分辨率训练  
✅ **预定义配置** - 避免手动修改多个文件  
✅ **生产级性能** - 充分利用H100/A800硬件能力  
✅ **完整部署** - 从测试到生产的无缝迁移  

### 快速参考

```bash
# 720×480 H100生产训练
./train_taehv_h100.sh 8 h100

# 720×480 A800测试训练  
./train_taehv_h100.sh 8 a800

# 从检查点恢复
./train_taehv_h100.sh 8 h100 --resume output/latest/checkpoint-5000

# 查看帮助
./train_taehv_h100.sh --help
```

现在您可以轻松地在不同GPU配置之间切换，获得最佳的训练性能！🚀
